// Generated by rstantools.  Do not edit by hand.

/*
    dynamicimpact is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    dynamicimpact is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with dynamicimpact.  If not, see <http://www.gnu.org/licenses/>.
*/
#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.21.0
#include <stan/model/model_header.hpp>
namespace model_vector_model_namespace {
using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;
static int current_statement_begin__;
stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_vector_model");
    reader.add_event(0, 0, "include", "include/utils.stan");
    reader.add_event(0, 0, "start", "include/utils.stan");
    reader.add_event(555, 555, "end", "include/utils.stan");
    reader.add_event(555, 1, "restart", "model_vector_model");
    reader.add_event(808, 252, "end", "model_vector_model");
    return reader;
}
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
relu(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 5;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 7;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 11;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 13;
            if (as_bool(logical_gt(get_base1(input, i, "input", 1), 0))) {
                current_statement_begin__ = 14;
                stan::model::assign(result, 
                            stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                            get_base1(input, i, "input", 1), 
                            "assigning variable result");
            } else {
                current_statement_begin__ = 16;
                stan::model::assign(result, 
                            stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                            0, 
                            "assigning variable result");
            }
        }
        current_statement_begin__ = 21;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct relu_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) const {
        return relu(input, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic, 1> >
cholesky_truncate_normal_base(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& mu,
                                  const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                  const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& b,
                                  const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& s,
                                  const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& u, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 28;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(mu));
        current_statement_begin__ = 28;
        validate_non_negative_index("d", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> d(K);
        stan::math::initialize(d, DUMMY_VAR__);
        stan::math::fill(d, DUMMY_VAR__);
        current_statement_begin__ = 28;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 28;
        validate_non_negative_index("out", "K", K);
        validate_non_negative_index("out", "2", 2);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > out(2, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(K));
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);
        current_statement_begin__ = 29;
        for (int k = 1; k <= K; ++k) {
            {
            current_statement_begin__ = 30;
            int km1(0);
            (void) km1;  // dummy to suppress unused var warning
            stan::math::fill(km1, std::numeric_limits<int>::min());
            stan::math::assign(km1,(k - 1));
            current_statement_begin__ = 31;
            if (as_bool(logical_neq(get_base1(s, k, "s", 1), 0))) {
                {
                current_statement_begin__ = 32;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                stan::math::assign(z_star,((get_base1(b, k, "b", 1) - (get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) ))) / get_base1(L, k, k, "L", 1)));
                current_statement_begin__ = 35;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 35;
                local_scalar_t__ u_star(DUMMY_VAR__);
                (void) u_star;  // dummy to suppress unused var warning
                stan::math::initialize(u_star, DUMMY_VAR__);
                stan::math::fill(u_star, DUMMY_VAR__);
                stan::math::assign(u_star,Phi(z_star));
                current_statement_begin__ = 36;
                if (as_bool(logical_eq(get_base1(s, k, "s", 1), -(1)))) {
                    current_statement_begin__ = 37;
                    stan::math::assign(v, (u_star * get_base1(u, k, "u", 1)));
                    current_statement_begin__ = 38;
                    stan::model::assign(d, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                u_star, 
                                "assigning variable d");
                } else {
                    current_statement_begin__ = 41;
                    stan::model::assign(d, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (1 - u_star), 
                                "assigning variable d");
                    current_statement_begin__ = 42;
                    stan::math::assign(v, (u_star + (get_base1(d, k, "d", 1) * get_base1(u, k, "u", 1))));
                }
                current_statement_begin__ = 44;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                }
            } else {
                current_statement_begin__ = 47;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
                current_statement_begin__ = 48;
                stan::model::assign(d, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            1, 
                            "assigning variable d");
            }
            }
        }
        current_statement_begin__ = 51;
        stan::model::assign(out, 
                    stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                    z, 
                    "assigning variable out");
        current_statement_begin__ = 52;
        stan::model::assign(out, 
                    stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                    d, 
                    "assigning variable out");
        current_statement_begin__ = 53;
        return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cholesky_truncate_normal_base_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic, 1> >
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& mu,
                                  const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                  const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& b,
                                  const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& s,
                                  const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& u, std::ostream* pstream__) const {
        return cholesky_truncate_normal_base(mu, L, b, s, u, pstream__);
    }
};
template <bool propto, typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
multi_normal_cholesky_truncated_lpdf(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 59;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 60;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 61;
        local_scalar_t__ lp(DUMMY_VAR__);
        (void) lp;  // dummy to suppress unused var warning
        stan::math::initialize(lp, DUMMY_VAR__);
        stan::math::fill(lp, DUMMY_VAR__);
        stan::math::assign(lp,0);
        current_statement_begin__ = 63;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 66;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 67;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 69;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 70;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 71;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 72;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 73;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 74;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 77;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 78;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 79;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 80;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 83;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 84;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 85;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                current_statement_begin__ = 86;
                stan::math::assign(lp, (lp + logd));
                }
            }
        }
        current_statement_begin__ = 89;
        return stan::math::promote_scalar<fun_return_scalar_t__>(lp);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
multi_normal_cholesky_truncated_lpdf(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) {
    return multi_normal_cholesky_truncated_lpdf<false>(u,mu,L,lb,ub,lb_ind,ub_ind, pstream__);
}
struct multi_normal_cholesky_truncated_lpdf_functor__ {
    template <bool propto, typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_lpdf(u, mu, L, lb, ub, lb_ind, ub_ind, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, class RNG>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type, Eigen::Dynamic, 1>
multi_normal_cholesky_truncated_rng(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                        const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                        const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                        const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                        const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                        const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                        const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 95;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 96;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 98;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 101;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 102;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 104;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 105;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 106;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 107;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 108;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 109;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 112;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 113;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 114;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 115;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 118;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 119;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 120;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                }
            }
        }
        current_statement_begin__ = 123;
        return stan::math::promote_scalar<fun_return_scalar_t__>(add(mu, multiply(L, z)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct multi_normal_cholesky_truncated_rng_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, class RNG>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                        const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                        const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                        const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                        const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                        const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                        const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, RNG& base_rng__, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_rng(u, mu, L, lb, ub, lb_ind, ub_ind, base_rng__, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T_lp__, typename T_lp_accum__>
void
multi_normal_cholesky_truncated_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                       const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                       const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                       const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                       const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T_lp__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 129;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 130;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 132;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 135;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 136;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 138;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 139;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 140;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 141;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 142;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 143;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 146;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 147;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 148;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 149;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 152;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 153;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 154;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                current_statement_begin__ = 155;
                lp_accum__.add(logd);
                }
            }
        }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct multi_normal_cholesky_truncated_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                       const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                       const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                       const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                       const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_lp(u, mu, L, lb, ub, lb_ind, ub_ind, lp__, lp_accum__, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, class RNG>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
truncate_multi_normal_rng(const T0__& lowerbound,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& Sigma, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 175;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(mu), 1, "dims(mu)", 1));
        current_statement_begin__ = 177;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 179;
        stan::math::assign(result, multi_normal_rng(mu, Sigma, base_rng__));
        current_statement_begin__ = 181;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct truncate_multi_normal_rng_functor__ {
    template <typename T0__, typename T1__, typename T2__, class RNG>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
    operator()(const T0__& lowerbound,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& Sigma, RNG& base_rng__, std::ostream* pstream__) const {
        return truncate_multi_normal_rng(lowerbound, mu, Sigma, base_rng__, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
pow_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& powers, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 187;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 189;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 191;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 192;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        pow(get_base1(input, i, "input", 1), get_base1(powers, i, "powers", 1)), 
                        "assigning variable result");
        }
        current_statement_begin__ = 195;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct pow_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& powers, std::ostream* pstream__) const {
        return pow_vector(input, powers, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
abs_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 201;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 203;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 205;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 206;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        stan::math::fabs(get_base1(input, i, "input", 1)), 
                        "assigning variable result");
        }
        current_statement_begin__ = 209;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct abs_vector_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) const {
        return abs_vector(input, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
vector_abs(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 215;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 216;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input), 2, "dims(input)", 1));
        current_statement_begin__ = 218;
        validate_non_negative_index("result", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 220;
        for (int i = 1; i <= ARRAY_LENGTH; ++i) {
            current_statement_begin__ = 221;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        abs_vector(get_base1(input, i, "input", 1), pstream__), 
                        "assigning variable result");
        }
        current_statement_begin__ = 224;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct vector_abs_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input, std::ostream* pstream__) const {
        return vector_abs(input, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__>
typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
elastic_net_regularizaion_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& params,
                                     const T1__& alpha1,
                                     const T2__& alpha2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 230;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(params), 1, "dims(params)", 1));
        current_statement_begin__ = 232;
        local_scalar_t__ result(DUMMY_VAR__);
        (void) result;  // dummy to suppress unused var warning
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 234;
        local_scalar_t__ squere_part(DUMMY_VAR__);
        (void) squere_part;  // dummy to suppress unused var warning
        stan::math::initialize(squere_part, DUMMY_VAR__);
        stan::math::fill(squere_part, DUMMY_VAR__);
        stan::math::assign(squere_part,(alpha1 * sum(pow_vector(params, rep_vector(2.0, N_SIZE), pstream__))));
        current_statement_begin__ = 236;
        local_scalar_t__ abs_part(DUMMY_VAR__);
        (void) abs_part;  // dummy to suppress unused var warning
        stan::math::initialize(abs_part, DUMMY_VAR__);
        stan::math::fill(abs_part, DUMMY_VAR__);
        stan::math::assign(abs_part,(alpha2 * sum(abs_vector(params, pstream__))));
        current_statement_begin__ = 238;
        stan::math::assign(result, (squere_part + abs_part));
        current_statement_begin__ = 240;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct elastic_net_regularizaion_vector_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& params,
                                     const T1__& alpha1,
                                     const T2__& alpha2, std::ostream* pstream__) const {
        return elastic_net_regularizaion_vector(params, alpha1, alpha2, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__>
typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
elastic_net_regularizaion(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& params,
                              const T1__& alpha1,
                              const T2__& alpha2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 246;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(params), 1, "dims(params)", 1));
        current_statement_begin__ = 247;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(params), 2, "dims(params)", 1));
        current_statement_begin__ = 249;
        local_scalar_t__ result(DUMMY_VAR__);
        (void) result;  // dummy to suppress unused var warning
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        stan::math::assign(result,0);
        current_statement_begin__ = 251;
        for (int j = 1; j <= VECTOR_LENGTH; ++j) {
            current_statement_begin__ = 253;
            stan::math::assign(result, (result + elastic_net_regularizaion_vector(to_vector(stan::model::rvalue(params, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "params")), alpha1, alpha2, pstream__)));
        }
        current_statement_begin__ = 257;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct elastic_net_regularizaion_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& params,
                              const T1__& alpha1,
                              const T2__& alpha2, std::ostream* pstream__) const {
        return elastic_net_regularizaion(params, alpha1, alpha2, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
kronecker_prod(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& A,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& B, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 265;
        validate_non_negative_index("C", "(rows(A) * rows(B))", (rows(A) * rows(B)));
        validate_non_negative_index("C", "(cols(A) * cols(B))", (cols(A) * cols(B)));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> C((rows(A) * rows(B)), (cols(A) * cols(B)));
        stan::math::initialize(C, DUMMY_VAR__);
        stan::math::fill(C, DUMMY_VAR__);
        stan::math::assign(C,rep_matrix(0.0, (rows(A) * rows(B)), (rows(A) * rows(B))));
        current_statement_begin__ = 266;
        int m(0);
        (void) m;  // dummy to suppress unused var warning
        stan::math::fill(m, std::numeric_limits<int>::min());
        current_statement_begin__ = 267;
        int n(0);
        (void) n;  // dummy to suppress unused var warning
        stan::math::fill(n, std::numeric_limits<int>::min());
        current_statement_begin__ = 268;
        int p(0);
        (void) p;  // dummy to suppress unused var warning
        stan::math::fill(p, std::numeric_limits<int>::min());
        current_statement_begin__ = 269;
        int q(0);
        (void) q;  // dummy to suppress unused var warning
        stan::math::fill(q, std::numeric_limits<int>::min());
        current_statement_begin__ = 271;
        stan::math::assign(m, rows(A));
        current_statement_begin__ = 272;
        stan::math::assign(n, cols(A));
        current_statement_begin__ = 273;
        stan::math::assign(p, rows(B));
        current_statement_begin__ = 274;
        stan::math::assign(q, cols(B));
        current_statement_begin__ = 276;
        if (as_bool((primitive_value(logical_eq(rows(A), 1)) && primitive_value(logical_eq(cols(A), 1))))) {
            current_statement_begin__ = 277;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(A, 1, 1, "A", 1), B));
        }
        current_statement_begin__ = 280;
        if (as_bool((primitive_value(logical_eq(rows(B), 1)) && primitive_value(logical_eq(cols(B), 1))))) {
            current_statement_begin__ = 281;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(B, 1, 1, "B", 1), A));
        }
        current_statement_begin__ = 284;
        for (int i = 1; i <= m; ++i) {
            current_statement_begin__ = 286;
            for (int j = 1; j <= n; ++j) {
                {
                current_statement_begin__ = 287;
                int row_start(0);
                (void) row_start;  // dummy to suppress unused var warning
                stan::math::fill(row_start, std::numeric_limits<int>::min());
                current_statement_begin__ = 288;
                int row_end(0);
                (void) row_end;  // dummy to suppress unused var warning
                stan::math::fill(row_end, std::numeric_limits<int>::min());
                current_statement_begin__ = 289;
                int col_start(0);
                (void) col_start;  // dummy to suppress unused var warning
                stan::math::fill(col_start, std::numeric_limits<int>::min());
                current_statement_begin__ = 290;
                int col_end(0);
                (void) col_end;  // dummy to suppress unused var warning
                stan::math::fill(col_end, std::numeric_limits<int>::min());
                current_statement_begin__ = 291;
                stan::math::assign(row_start, (((i - 1) * p) + 1));
                current_statement_begin__ = 292;
                stan::math::assign(row_end, (((i - 1) * p) + p));
                current_statement_begin__ = 293;
                stan::math::assign(col_start, (((j - 1) * q) + 1));
                current_statement_begin__ = 294;
                stan::math::assign(col_end, (((j - 1) * q) + q));
                current_statement_begin__ = 295;
                stan::model::assign(C, 
                            stan::model::cons_list(stan::model::index_min_max(row_start, row_end), stan::model::cons_list(stan::model::index_min_max(col_start, col_end), stan::model::nil_index_list())), 
                            multiply(get_base1(A, i, j, "A", 1), B), 
                            "assigning variable C");
                }
            }
        }
        current_statement_begin__ = 300;
        return stan::math::promote_scalar<fun_return_scalar_t__>(C);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct kronecker_prod_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& A,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& B, std::ostream* pstream__) const {
        return kronecker_prod(A, B, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type
log_matrix_normal_density(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& y_real,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& y_est,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& V,
                              const Eigen::Matrix<T3__, Eigen::Dynamic, Eigen::Dynamic>& U, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 307;
        local_scalar_t__ det_V(DUMMY_VAR__);
        (void) det_V;  // dummy to suppress unused var warning
        stan::math::initialize(det_V, DUMMY_VAR__);
        stan::math::fill(det_V, DUMMY_VAR__);
        stan::math::assign(det_V,determinant(V));
        current_statement_begin__ = 308;
        local_scalar_t__ det_U(DUMMY_VAR__);
        (void) det_U;  // dummy to suppress unused var warning
        stan::math::initialize(det_U, DUMMY_VAR__);
        stan::math::fill(det_U, DUMMY_VAR__);
        stan::math::assign(det_U,determinant(U));
        current_statement_begin__ = 312;
        validate_non_negative_index("inv_V", "get_base1(dims(V), 1, \"dims(V)\", 1)", get_base1(dims(V), 1, "dims(V)", 1));
        validate_non_negative_index("inv_V", "get_base1(dims(V), 2, \"dims(V)\", 1)", get_base1(dims(V), 2, "dims(V)", 1));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> inv_V(get_base1(dims(V), 1, "dims(V)", 1), get_base1(dims(V), 2, "dims(V)", 1));
        stan::math::initialize(inv_V, DUMMY_VAR__);
        stan::math::fill(inv_V, DUMMY_VAR__);
        stan::math::assign(inv_V,inverse_spd(V));
        current_statement_begin__ = 313;
        validate_non_negative_index("inv_U", "get_base1(dims(U), 1, \"dims(U)\", 1)", get_base1(dims(U), 1, "dims(U)", 1));
        validate_non_negative_index("inv_U", "get_base1(dims(U), 2, \"dims(U)\", 1)", get_base1(dims(U), 2, "dims(U)", 1));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> inv_U(get_base1(dims(U), 1, "dims(U)", 1), get_base1(dims(U), 2, "dims(U)", 1));
        stan::math::initialize(inv_U, DUMMY_VAR__);
        stan::math::fill(inv_U, DUMMY_VAR__);
        stan::math::assign(inv_U,inverse_spd(U));
        current_statement_begin__ = 315;
        int n(0);
        (void) n;  // dummy to suppress unused var warning
        stan::math::fill(n, std::numeric_limits<int>::min());
        stan::math::assign(n,get_base1(dims(y_real), 1, "dims(y_real)", 1));
        current_statement_begin__ = 316;
        int p(0);
        (void) p;  // dummy to suppress unused var warning
        stan::math::fill(p, std::numeric_limits<int>::min());
        stan::math::assign(p,get_base1(dims(y_real), 2, "dims(y_real)", 1));
        current_statement_begin__ = 319;
        validate_non_negative_index("temp_matrix", "p", p);
        validate_non_negative_index("temp_matrix", "p", p);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> temp_matrix(p, p);
        stan::math::initialize(temp_matrix, DUMMY_VAR__);
        stan::math::fill(temp_matrix, DUMMY_VAR__);
        stan::math::assign(temp_matrix,multiply((-(1) / 2.0), multiply(multiply(multiply(inv_V, transpose(subtract(y_real, y_est))), inv_U), subtract(y_real, y_est))));
        current_statement_begin__ = 322;
        local_scalar_t__ result_value(DUMMY_VAR__);
        (void) result_value;  // dummy to suppress unused var warning
        stan::math::initialize(result_value, DUMMY_VAR__);
        stan::math::fill(result_value, DUMMY_VAR__);
        stan::math::assign(result_value,(((trace(temp_matrix) - stan::math::log(pow((2.0 * stan::math::pi()), (((1.0 * n) * p) / 2.0)))) - stan::math::log(pow(det_V, ((1.0 * n) / 2.0)))) - stan::math::log(pow(det_U, ((1.0 * p) / 2.0)))));
        current_statement_begin__ = 324;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_value);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct log_matrix_normal_density_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& y_real,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& y_est,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& V,
                              const Eigen::Matrix<T3__, Eigen::Dynamic, Eigen::Dynamic>& U, std::ostream* pstream__) const {
        return log_matrix_normal_density(y_real, y_est, V, U, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
cumsum_matrix(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 330;
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 2, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 3, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 3, "dims(input_matrix)", 1));
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 1, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix(get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1), Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1), get_base1(dims(input_matrix), 3, "dims(input_matrix)", 1)));
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 332;
        for (int t = 1; t <= get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1); ++t) {
            current_statement_begin__ = 334;
            if (as_bool(logical_eq(t, 1))) {
                current_statement_begin__ = 335;
                stan::model::assign(result_matrix, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            get_base1(input_matrix, t, "input_matrix", 1), 
                            "assigning variable result_matrix");
            } else {
                current_statement_begin__ = 337;
                stan::model::assign(result_matrix, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            add(get_base1(result_matrix, (t - 1), "result_matrix", 1), get_base1(input_matrix, t, "input_matrix", 1)), 
                            "assigning variable result_matrix");
            }
        }
        current_statement_begin__ = 341;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cumsum_matrix_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix, std::ostream* pstream__) const {
        return cumsum_matrix(input_matrix, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
cumsum_vector(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 347;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 349;
        validate_non_negative_index("result_vector", "get_base1(dims(input_vector), 2, \"dims(input_vector)\", 1)", get_base1(dims(input_vector), 2, "dims(input_vector)", 1));
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_vector(N_SIZE, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(get_base1(dims(input_vector), 2, "dims(input_vector)", 1)));
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 351;
        stan::model::assign(result_vector, 
                    stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                    get_base1(input_vector, 1, "input_vector", 1), 
                    "assigning variable result_vector");
        current_statement_begin__ = 353;
        for (int t = 2; t <= N_SIZE; ++t) {
            current_statement_begin__ = 354;
            stan::model::assign(result_vector, 
                        stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                        add(get_base1(result_vector, (t - 1), "result_vector", 1), get_base1(input_vector, t, "input_vector", 1)), 
                        "assigning variable result_vector");
        }
        current_statement_begin__ = 357;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cumsum_vector_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector, std::ostream* pstream__) const {
        return cumsum_vector(input_vector, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
scale_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                 const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 362;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 364;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result_vector(N_SIZE);
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 365;
        validate_non_negative_index("log_input_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> log_input_vector(N_SIZE);
        stan::math::initialize(log_input_vector, DUMMY_VAR__);
        stan::math::fill(log_input_vector, DUMMY_VAR__);
        current_statement_begin__ = 367;
        if (as_bool(use_log)) {
            current_statement_begin__ = 368;
            stan::math::assign(log_input_vector, stan::math::log(input_vector));
            current_statement_begin__ = 369;
            stan::math::assign(result_vector, divide(subtract(log_input_vector, mean(log_input_vector)), sd(log_input_vector)));
        } else {
            current_statement_begin__ = 371;
            stan::math::assign(result_vector, divide(subtract(input_vector, mean(input_vector)), sd(input_vector)));
        }
        current_statement_begin__ = 375;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_vector_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                 const int& use_log, std::ostream* pstream__) const {
        return scale_vector(input_vector, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
unscale_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& original_vector,
                   const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 383;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 384;
        int N_SIZE_ORIGINAL(0);
        (void) N_SIZE_ORIGINAL;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE_ORIGINAL, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE_ORIGINAL,get_base1(dims(original_vector), 1, "dims(original_vector)", 1));
        current_statement_begin__ = 386;
        validate_non_negative_index("log_original_vector", "N_SIZE_ORIGINAL", N_SIZE_ORIGINAL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> log_original_vector(N_SIZE_ORIGINAL);
        stan::math::initialize(log_original_vector, DUMMY_VAR__);
        stan::math::fill(log_original_vector, DUMMY_VAR__);
        current_statement_begin__ = 387;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result_vector(N_SIZE);
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 390;
        if (as_bool(use_log)) {
            current_statement_begin__ = 392;
            stan::math::assign(log_original_vector, stan::math::log(original_vector));
            current_statement_begin__ = 394;
            stan::math::assign(result_vector, add(multiply(sd(log_original_vector), input_vector), mean(log_original_vector)));
            current_statement_begin__ = 395;
            stan::math::assign(result_vector, stan::math::exp(result_vector));
        } else {
            current_statement_begin__ = 399;
            stan::math::assign(result_vector, add(multiply(sd(original_vector), input_vector), mean(original_vector)));
        }
        current_statement_begin__ = 404;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& original_vector,
                   const int& use_log, std::ostream* pstream__) const {
        return unscale_vector(input_vector, original_vector, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<typename boost::math::tools::promote_args<T0__, T1__>::type>
unscale_array(const std::vector<T0__>& input_vector,
                  const std::vector<T1__>& original_vector,
                  const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 410;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 412;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        std::vector<local_scalar_t__  > result_vector(N_SIZE, local_scalar_t__(DUMMY_VAR__));
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 414;
        stan::math::assign(result_vector, to_array_1d(unscale_vector(to_vector(input_vector), to_vector(original_vector), use_log, pstream__)));
        current_statement_begin__ = 417;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<typename boost::math::tools::promote_args<T0__, T1__>::type>
    operator()(const std::vector<T0__>& input_vector,
                  const std::vector<T1__>& original_vector,
                  const int& use_log, std::ostream* pstream__) const {
        return unscale_array(input_vector, original_vector, use_log, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
scale_matrix(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                 const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 423;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 424;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 427;
        validate_non_negative_index("result_matrix", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix(N_ROW, N_COL);
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 429;
        for (int j = 1; j <= N_COL; ++j) {
            current_statement_begin__ = 431;
            stan::model::assign(result_matrix, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        scale_vector(stan::model::rvalue(input_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_matrix"), use_log, pstream__), 
                        "assigning variable result_matrix");
        }
        current_statement_begin__ = 435;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_matrix_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                 const int& use_log, std::ostream* pstream__) const {
        return scale_matrix(input_matrix, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
unscale_matrix(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& original_matrix,
                   const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 441;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 442;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 445;
        validate_non_negative_index("result_matrix", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix(N_ROW, N_COL);
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 447;
        for (int j = 1; j <= N_COL; ++j) {
            current_statement_begin__ = 449;
            stan::model::assign(result_matrix, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        unscale_vector(stan::model::rvalue(input_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_matrix"), stan::model::rvalue(original_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "original_matrix"), use_log, pstream__), 
                        "assigning variable result_matrix");
        }
        current_statement_begin__ = 453;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_matrix_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& original_matrix,
                   const int& use_log, std::ostream* pstream__) const {
        return unscale_matrix(input_matrix, original_matrix, use_log, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
scale_matrix_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                       const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 459;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_matrix_array), 1, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 460;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix_array), 2, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 461;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix_array), 3, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 464;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        validate_non_negative_index("result_matrix_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(N_ROW, N_COL));
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 466;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 468;
            stan::model::assign(result_matrix_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        scale_matrix(get_base1(input_matrix_array, j, "input_matrix_array", 1), use_log, pstream__), 
                        "assigning variable result_matrix_array");
        }
        current_statement_begin__ = 472;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_matrix_array_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                       const int& use_log, std::ostream* pstream__) const {
        return scale_matrix_array(input_matrix_array, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic> >
unscale_matrix_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic> >& original_matrix_array,
                         const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 479;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_matrix_array), 1, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 480;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix_array), 2, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 481;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix_array), 3, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 484;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        validate_non_negative_index("result_matrix_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(N_ROW, N_COL));
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 486;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 488;
            stan::model::assign(result_matrix_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        unscale_matrix(get_base1(input_matrix_array, j, "input_matrix_array", 1), get_base1(original_matrix_array, j, "original_matrix_array", 1), use_log, pstream__), 
                        "assigning variable result_matrix_array");
        }
        current_statement_begin__ = 492;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_matrix_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic> >& original_matrix_array,
                         const int& use_log, std::ostream* pstream__) const {
        return unscale_matrix_array(input_matrix_array, original_matrix_array, use_log, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
scale_vector_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                       const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 499;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_vector_array), 1, "dims(input_vector_array)", 1));
        current_statement_begin__ = 500;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input_vector_array), 2, "dims(input_vector_array)", 1));
        current_statement_begin__ = 503;
        validate_non_negative_index("result_array", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result_array, DUMMY_VAR__);
        stan::math::fill(result_array, DUMMY_VAR__);
        current_statement_begin__ = 505;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 507;
            stan::model::assign(result_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        scale_vector(get_base1(input_vector_array, j, "input_vector_array", 1), use_log, pstream__), 
                        "assigning variable result_array");
        }
        current_statement_begin__ = 511;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_vector_array_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                       const int& use_log, std::ostream* pstream__) const {
        return scale_vector_array(input_vector_array, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1> >
unscale_vector_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, 1> >& original_vector_array,
                         const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 519;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_vector_array), 1, "dims(input_vector_array)", 1));
        current_statement_begin__ = 520;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input_vector_array), 2, "dims(input_vector_array)", 1));
        current_statement_begin__ = 523;
        validate_non_negative_index("result_array", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result_array, DUMMY_VAR__);
        stan::math::fill(result_array, DUMMY_VAR__);
        current_statement_begin__ = 525;
        for (int j = 1; j <= VECTOR_LENGTH; ++j) {
            current_statement_begin__ = 527;
            stan::model::assign(result_array, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        unscale_array(stan::model::rvalue(input_vector_array, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_vector_array"), stan::model::rvalue(original_vector_array, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "original_vector_array"), use_log, pstream__), 
                        "assigning variable result_array");
        }
        current_statement_begin__ = 531;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_vector_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, 1> >& original_vector_array,
                         const int& use_log, std::ostream* pstream__) const {
        return unscale_vector_array(input_vector_array, original_vector_array, use_log, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
cov_matrix_correction(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 537;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 538;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 540;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix_array(N_ROW, N_COL);
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 542;
        stan::math::assign(result_matrix_array, add(multiply(0.5, add(input_matrix, transpose(input_matrix))), diag_matrix(rep_vector(1e-9, N_ROW))));
        current_statement_begin__ = 545;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cov_matrix_correction_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix, std::ostream* pstream__) const {
        return cov_matrix_correction(input_matrix, pstream__);
    }
};
#include <stan_meta_header.hpp>
class model_vector_model
  : public stan::model::model_base_crtp<model_vector_model> {
private:
        int T;
        int T0;
        int K;
        int P;
        std::vector<vector_d> Y;
        std::vector<vector_d> X;
        int use_log;
        int scale;
        int force_positive;
        vector_d lb;
        vector_d ub;
        vector_d s;
        double obs_scale;
        double evol_scale;
        double eta_obs;
        double eta_evol;
        int T_after;
        std::vector<vector_d> X_before;
        std::vector<vector_d> X_after;
        std::vector<vector_d> X_fit;
        std::vector<vector_d> X_fit_before;
        std::vector<vector_d> X_fit_after;
        std::vector<vector_d> Y_before;
        std::vector<vector_d> Y_after;
        std::vector<vector_d> Y_fit_before;
        std::vector<vector_d> Y_fit_after;
        std::vector<vector_d> Y_fit;
public:
    model_vector_model(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, 0, pstream__);
    }
    model_vector_model(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, random_seed__, pstream__);
    }
    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        typedef double local_scalar_t__;
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning
        current_statement_begin__ = -1;
        static const char* function__ = "model_vector_model_namespace::model_vector_model";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
        try {
            // initialize data block variables from context__
            current_statement_begin__ = 559;
            context__.validate_dims("data initialization", "T", "int", context__.to_vec());
            T = int(0);
            vals_i__ = context__.vals_i("T");
            pos__ = 0;
            T = vals_i__[pos__++];
            check_greater_or_equal(function__, "T", T, 1);
            current_statement_begin__ = 560;
            context__.validate_dims("data initialization", "T0", "int", context__.to_vec());
            T0 = int(0);
            vals_i__ = context__.vals_i("T0");
            pos__ = 0;
            T0 = vals_i__[pos__++];
            check_greater_or_equal(function__, "T0", T0, 1);
            check_less_or_equal(function__, "T0", T0, T);
            current_statement_begin__ = 563;
            context__.validate_dims("data initialization", "K", "int", context__.to_vec());
            K = int(0);
            vals_i__ = context__.vals_i("K");
            pos__ = 0;
            K = vals_i__[pos__++];
            check_greater_or_equal(function__, "K", K, 0);
            current_statement_begin__ = 564;
            context__.validate_dims("data initialization", "P", "int", context__.to_vec());
            P = int(0);
            vals_i__ = context__.vals_i("P");
            pos__ = 0;
            P = vals_i__[pos__++];
            check_greater_or_equal(function__, "P", P, 0);
            current_statement_begin__ = 566;
            validate_non_negative_index("Y", "K", K);
            validate_non_negative_index("Y", "T", T);
            context__.validate_dims("data initialization", "Y", "vector_d", context__.to_vec(T,K));
            Y = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            vals_r__ = context__.vals_r("Y");
            pos__ = 0;
            size_t Y_j_1_max__ = K;
            size_t Y_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < Y_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < Y_k_0_max__; ++k_0__) {
                    Y[k_0__](j_1__) = vals_r__[pos__++];
                }
            }
            size_t Y_i_0_max__ = T;
            for (size_t i_0__ = 0; i_0__ < Y_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "Y[i_0__]", Y[i_0__], 0);
            }
            current_statement_begin__ = 567;
            validate_non_negative_index("X", "P", P);
            validate_non_negative_index("X", "T", T);
            context__.validate_dims("data initialization", "X", "vector_d", context__.to_vec(T,P));
            X = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            vals_r__ = context__.vals_r("X");
            pos__ = 0;
            size_t X_j_1_max__ = P;
            size_t X_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < X_k_0_max__; ++k_0__) {
                    X[k_0__](j_1__) = vals_r__[pos__++];
                }
            }
            size_t X_i_0_max__ = T;
            for (size_t i_0__ = 0; i_0__ < X_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "X[i_0__]", X[i_0__], 0);
            }
            current_statement_begin__ = 569;
            context__.validate_dims("data initialization", "use_log", "int", context__.to_vec());
            use_log = int(0);
            vals_i__ = context__.vals_i("use_log");
            pos__ = 0;
            use_log = vals_i__[pos__++];
            check_greater_or_equal(function__, "use_log", use_log, 0);
            check_less_or_equal(function__, "use_log", use_log, 1);
            current_statement_begin__ = 570;
            context__.validate_dims("data initialization", "scale", "int", context__.to_vec());
            scale = int(0);
            vals_i__ = context__.vals_i("scale");
            pos__ = 0;
            scale = vals_i__[pos__++];
            check_greater_or_equal(function__, "scale", scale, 0);
            check_less_or_equal(function__, "scale", scale, 1);
            current_statement_begin__ = 571;
            context__.validate_dims("data initialization", "force_positive", "int", context__.to_vec());
            force_positive = int(0);
            vals_i__ = context__.vals_i("force_positive");
            pos__ = 0;
            force_positive = vals_i__[pos__++];
            check_greater_or_equal(function__, "force_positive", force_positive, 0);
            check_less_or_equal(function__, "force_positive", force_positive, 1);
            current_statement_begin__ = 573;
            validate_non_negative_index("lb", "K", K);
            context__.validate_dims("data initialization", "lb", "vector_d", context__.to_vec(K));
            lb = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("lb");
            pos__ = 0;
            size_t lb_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < lb_j_1_max__; ++j_1__) {
                lb(j_1__) = vals_r__[pos__++];
            }
            current_statement_begin__ = 574;
            validate_non_negative_index("ub", "K", K);
            context__.validate_dims("data initialization", "ub", "vector_d", context__.to_vec(K));
            ub = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("ub");
            pos__ = 0;
            size_t ub_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < ub_j_1_max__; ++j_1__) {
                ub(j_1__) = vals_r__[pos__++];
            }
            current_statement_begin__ = 580;
            validate_non_negative_index("s", "K", K);
            context__.validate_dims("data initialization", "s", "vector_d", context__.to_vec(K));
            s = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("s");
            pos__ = 0;
            size_t s_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < s_j_1_max__; ++j_1__) {
                s(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "s", s, -(1));
            check_less_or_equal(function__, "s", s, 1);
            current_statement_begin__ = 582;
            context__.validate_dims("data initialization", "obs_scale", "double", context__.to_vec());
            obs_scale = double(0);
            vals_r__ = context__.vals_r("obs_scale");
            pos__ = 0;
            obs_scale = vals_r__[pos__++];
            check_greater_or_equal(function__, "obs_scale", obs_scale, 0);
            current_statement_begin__ = 583;
            context__.validate_dims("data initialization", "evol_scale", "double", context__.to_vec());
            evol_scale = double(0);
            vals_r__ = context__.vals_r("evol_scale");
            pos__ = 0;
            evol_scale = vals_r__[pos__++];
            check_greater_or_equal(function__, "evol_scale", evol_scale, 0);
            current_statement_begin__ = 585;
            context__.validate_dims("data initialization", "eta_obs", "double", context__.to_vec());
            eta_obs = double(0);
            vals_r__ = context__.vals_r("eta_obs");
            pos__ = 0;
            eta_obs = vals_r__[pos__++];
            check_greater_or_equal(function__, "eta_obs", eta_obs, 0);
            current_statement_begin__ = 586;
            context__.validate_dims("data initialization", "eta_evol", "double", context__.to_vec());
            eta_evol = double(0);
            vals_r__ = context__.vals_r("eta_evol");
            pos__ = 0;
            eta_evol = vals_r__[pos__++];
            check_greater_or_equal(function__, "eta_evol", eta_evol, 0);
            // initialize transformed data variables
            current_statement_begin__ = 594;
            T_after = int(0);
            stan::math::fill(T_after, std::numeric_limits<int>::min());
            stan::math::assign(T_after,(T - T0));
            current_statement_begin__ = 596;
            validate_non_negative_index("X_before", "P", P);
            validate_non_negative_index("X_before", "T0", T0);
            X_before = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            stan::math::fill(X_before, DUMMY_VAR__);
            current_statement_begin__ = 597;
            validate_non_negative_index("X_after", "P", P);
            validate_non_negative_index("X_after", "T_after", T_after);
            X_after = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T_after, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            stan::math::fill(X_after, DUMMY_VAR__);
            current_statement_begin__ = 599;
            validate_non_negative_index("X_fit", "P", P);
            validate_non_negative_index("X_fit", "T", T);
            X_fit = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            stan::math::fill(X_fit, DUMMY_VAR__);
            current_statement_begin__ = 600;
            validate_non_negative_index("X_fit_before", "P", P);
            validate_non_negative_index("X_fit_before", "T0", T0);
            X_fit_before = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            stan::math::fill(X_fit_before, DUMMY_VAR__);
            current_statement_begin__ = 601;
            validate_non_negative_index("X_fit_after", "P", P);
            validate_non_negative_index("X_fit_after", "T_after", T_after);
            X_fit_after = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T_after, Eigen::Matrix<double, Eigen::Dynamic, 1>(P));
            stan::math::fill(X_fit_after, DUMMY_VAR__);
            current_statement_begin__ = 603;
            validate_non_negative_index("Y_before", "K", K);
            validate_non_negative_index("Y_before", "T0", T0);
            Y_before = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::fill(Y_before, DUMMY_VAR__);
            current_statement_begin__ = 604;
            validate_non_negative_index("Y_after", "K", K);
            validate_non_negative_index("Y_after", "T_after", T_after);
            Y_after = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T_after, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::fill(Y_after, DUMMY_VAR__);
            current_statement_begin__ = 606;
            validate_non_negative_index("Y_fit_before", "K", K);
            validate_non_negative_index("Y_fit_before", "T0", T0);
            Y_fit_before = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::fill(Y_fit_before, DUMMY_VAR__);
            current_statement_begin__ = 607;
            validate_non_negative_index("Y_fit_after", "K", K);
            validate_non_negative_index("Y_fit_after", "T_after", T_after);
            Y_fit_after = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T_after, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::fill(Y_fit_after, DUMMY_VAR__);
            current_statement_begin__ = 608;
            validate_non_negative_index("Y_fit", "K", K);
            validate_non_negative_index("Y_fit", "T", T);
            Y_fit = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::fill(Y_fit, DUMMY_VAR__);
            // execute transformed data statements
            current_statement_begin__ = 610;
            stan::math::assign(X_before, stan::model::rvalue(X, stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), "X"));
            current_statement_begin__ = 611;
            stan::math::assign(X_after, stan::model::rvalue(X, stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "X"));
            current_statement_begin__ = 613;
            stan::math::assign(Y_before, stan::model::rvalue(Y, stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), "Y"));
            current_statement_begin__ = 614;
            stan::math::assign(Y_after, stan::model::rvalue(Y, stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "Y"));
            current_statement_begin__ = 616;
            if (as_bool(scale)) {
                current_statement_begin__ = 618;
                stan::math::assign(Y_fit_before, stan::model::rvalue(scale_vector_array(Y, use_log, pstream__), stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), "scale_vector_array(Y, use_log, pstream__)"));
                current_statement_begin__ = 619;
                stan::math::assign(Y_fit_after, stan::model::rvalue(scale_vector_array(Y, use_log, pstream__), stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "scale_vector_array(Y, use_log, pstream__)"));
                current_statement_begin__ = 620;
                stan::math::assign(Y_fit, scale_vector_array(Y, use_log, pstream__));
                current_statement_begin__ = 622;
                stan::math::assign(X_fit_before, stan::model::rvalue(scale_vector_array(X, use_log, pstream__), stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), "scale_vector_array(X, use_log, pstream__)"));
                current_statement_begin__ = 623;
                stan::math::assign(X_fit_after, stan::model::rvalue(scale_vector_array(X, use_log, pstream__), stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "scale_vector_array(X, use_log, pstream__)"));
                current_statement_begin__ = 624;
                stan::math::assign(X_fit, scale_vector_array(X, use_log, pstream__));
            } else {
                current_statement_begin__ = 628;
                if (as_bool(use_log)) {
                    current_statement_begin__ = 630;
                    stan::math::assign(Y_fit_before, stan::math::log(Y_before));
                    current_statement_begin__ = 631;
                    stan::math::assign(Y_fit_after, stan::math::log(Y_fit_after));
                    current_statement_begin__ = 632;
                    stan::math::assign(Y_fit, stan::math::log(Y_fit));
                    current_statement_begin__ = 634;
                    stan::math::assign(X_fit_before, stan::math::log(X_before));
                    current_statement_begin__ = 635;
                    stan::math::assign(X_fit_after, stan::math::log(X_after));
                    current_statement_begin__ = 636;
                    stan::math::assign(X_fit, stan::math::log(X));
                } else {
                    current_statement_begin__ = 640;
                    stan::math::assign(Y_fit_before, Y_before);
                    current_statement_begin__ = 641;
                    stan::math::assign(Y_fit_after, Y_after);
                    current_statement_begin__ = 642;
                    stan::math::assign(Y_fit, Y);
                    current_statement_begin__ = 644;
                    stan::math::assign(X_fit_before, X_before);
                    current_statement_begin__ = 645;
                    stan::math::assign(X_fit_after, X_after);
                    current_statement_begin__ = 646;
                    stan::math::assign(X_fit, X);
                }
            }
            // validate transformed data
            // validate, set parameter ranges
            num_params_r__ = 0U;
            param_ranges_i__.clear();
            current_statement_begin__ = 658;
            validate_non_negative_index("sigma_entry_cholesky", "K", K);
            validate_non_negative_index("sigma_entry_cholesky", "K", K);
            num_params_r__ += (((K * (K + 1)) / 2) + ((K - K) * K));
            current_statement_begin__ = 659;
            validate_non_negative_index("tau", "K", K);
            num_params_r__ += K;
            current_statement_begin__ = 660;
            validate_non_negative_index("sigma", "(P * K)", (P * K));
            num_params_r__ += (P * K);
            current_statement_begin__ = 663;
            validate_non_negative_index("theta_vec", "(P * K)", (P * K));
            validate_non_negative_index("theta_vec", "T0", T0);
            num_params_r__ += ((P * K) * T0);
            current_statement_begin__ = 667;
            validate_non_negative_index("theta_vec_cholesky_matrix", "(P * K)", (P * K));
            validate_non_negative_index("theta_vec_cholesky_matrix", "(P * K)", (P * K));
            num_params_r__ += ((((P * K) * ((P * K) + 1)) / 2) + (((P * K) - (P * K)) * (P * K)));
            current_statement_begin__ = 670;
            validate_non_negative_index("u", "K", K);
            num_params_r__ += K;
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }
    ~model_vector_model() { }
    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        typedef double local_scalar_t__;
        stan::io::writer<double> writer__(params_r__, params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;
        current_statement_begin__ = 658;
        if (!(context__.contains_r("sigma_entry_cholesky")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable sigma_entry_cholesky missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("sigma_entry_cholesky");
        pos__ = 0U;
        validate_non_negative_index("sigma_entry_cholesky", "K", K);
        validate_non_negative_index("sigma_entry_cholesky", "K", K);
        context__.validate_dims("parameter initialization", "sigma_entry_cholesky", "matrix_d", context__.to_vec(K,K));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_cholesky(K, K);
        size_t sigma_entry_cholesky_j_2_max__ = K;
        size_t sigma_entry_cholesky_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_cholesky_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_cholesky_j_1_max__; ++j_1__) {
                sigma_entry_cholesky(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cholesky_factor_cov_unconstrain(sigma_entry_cholesky);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable sigma_entry_cholesky: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 659;
        if (!(context__.contains_r("tau")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable tau missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "K", K);
        context__.validate_dims("parameter initialization", "tau", "vector_d", context__.to_vec(K));
        Eigen::Matrix<double, Eigen::Dynamic, 1> tau(K);
        size_t tau_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            tau(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, tau);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable tau: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 660;
        if (!(context__.contains_r("sigma")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable sigma missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("sigma");
        pos__ = 0U;
        validate_non_negative_index("sigma", "(P * K)", (P * K));
        context__.validate_dims("parameter initialization", "sigma", "vector_d", context__.to_vec((P * K)));
        Eigen::Matrix<double, Eigen::Dynamic, 1> sigma((P * K));
        size_t sigma_j_1_max__ = (P * K);
        for (size_t j_1__ = 0; j_1__ < sigma_j_1_max__; ++j_1__) {
            sigma(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, sigma);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable sigma: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 663;
        if (!(context__.contains_r("theta_vec")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable theta_vec missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("theta_vec");
        pos__ = 0U;
        validate_non_negative_index("theta_vec", "(P * K)", (P * K));
        validate_non_negative_index("theta_vec", "T0", T0);
        context__.validate_dims("parameter initialization", "theta_vec", "vector_d", context__.to_vec(T0,(P * K)));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > theta_vec(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>((P * K)));
        size_t theta_vec_j_1_max__ = (P * K);
        size_t theta_vec_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_vec_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_k_0_max__; ++k_0__) {
                theta_vec[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t theta_vec_i_0_max__ = T0;
        for (size_t i_0__ = 0; i_0__ < theta_vec_i_0_max__; ++i_0__) {
            try {
                writer__.vector_unconstrain(theta_vec[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable theta_vec: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }
        current_statement_begin__ = 667;
        if (!(context__.contains_r("theta_vec_cholesky_matrix")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable theta_vec_cholesky_matrix missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("theta_vec_cholesky_matrix");
        pos__ = 0U;
        validate_non_negative_index("theta_vec_cholesky_matrix", "(P * K)", (P * K));
        validate_non_negative_index("theta_vec_cholesky_matrix", "(P * K)", (P * K));
        context__.validate_dims("parameter initialization", "theta_vec_cholesky_matrix", "matrix_d", context__.to_vec((P * K),(P * K)));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> theta_vec_cholesky_matrix((P * K), (P * K));
        size_t theta_vec_cholesky_matrix_j_2_max__ = (P * K);
        size_t theta_vec_cholesky_matrix_j_1_max__ = (P * K);
        for (size_t j_2__ = 0; j_2__ < theta_vec_cholesky_matrix_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < theta_vec_cholesky_matrix_j_1_max__; ++j_1__) {
                theta_vec_cholesky_matrix(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cholesky_factor_cov_unconstrain(theta_vec_cholesky_matrix);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable theta_vec_cholesky_matrix: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 670;
        if (!(context__.contains_r("u")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable u missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("u");
        pos__ = 0U;
        validate_non_negative_index("u", "K", K);
        context__.validate_dims("parameter initialization", "u", "vector_d", context__.to_vec(K));
        Eigen::Matrix<double, Eigen::Dynamic, 1> u(K);
        size_t u_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < u_j_1_max__; ++j_1__) {
            u(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lub_unconstrain(0, 1, u);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable u: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }
    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double, Eigen::Dynamic, 1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }
    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(std::vector<T__>& params_r__,
                 std::vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {
        typedef T__ local_scalar_t__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // dummy to suppress unused var warning
        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;
        try {
            stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
            // model parameters
            current_statement_begin__ = 658;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_cholesky;
            (void) sigma_entry_cholesky;  // dummy to suppress unused var warning
            if (jacobian__)
                sigma_entry_cholesky = in__.cholesky_factor_cov_constrain(K, K, lp__);
            else
                sigma_entry_cholesky = in__.cholesky_factor_cov_constrain(K, K);
            current_statement_begin__ = 659;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> tau;
            (void) tau;  // dummy to suppress unused var warning
            if (jacobian__)
                tau = in__.vector_lb_constrain(0, K, lp__);
            else
                tau = in__.vector_lb_constrain(0, K);
            current_statement_begin__ = 660;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> sigma;
            (void) sigma;  // dummy to suppress unused var warning
            if (jacobian__)
                sigma = in__.vector_lb_constrain(0, (P * K), lp__);
            else
                sigma = in__.vector_lb_constrain(0, (P * K));
            current_statement_begin__ = 663;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > theta_vec;
            size_t theta_vec_d_0_max__ = T0;
            theta_vec.reserve(theta_vec_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < theta_vec_d_0_max__; ++d_0__) {
                if (jacobian__)
                    theta_vec.push_back(in__.vector_constrain((P * K), lp__));
                else
                    theta_vec.push_back(in__.vector_constrain((P * K)));
            }
            current_statement_begin__ = 667;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> theta_vec_cholesky_matrix;
            (void) theta_vec_cholesky_matrix;  // dummy to suppress unused var warning
            if (jacobian__)
                theta_vec_cholesky_matrix = in__.cholesky_factor_cov_constrain((P * K), (P * K), lp__);
            else
                theta_vec_cholesky_matrix = in__.cholesky_factor_cov_constrain((P * K), (P * K));
            current_statement_begin__ = 670;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> u;
            (void) u;  // dummy to suppress unused var warning
            if (jacobian__)
                u = in__.vector_lub_constrain(0, 1, K, lp__);
            else
                u = in__.vector_lub_constrain(0, 1, K);
            // transformed parameters
            current_statement_begin__ = 676;
            validate_non_negative_index("L", "K", K);
            validate_non_negative_index("L", "K", K);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> L(K, K);
            stan::math::initialize(L, DUMMY_VAR__);
            stan::math::fill(L, DUMMY_VAR__);
            stan::math::assign(L,diag_pre_multiply(tau, sigma_entry_cholesky));
            current_statement_begin__ = 677;
            validate_non_negative_index("L_evol", "(P * K)", (P * K));
            validate_non_negative_index("L_evol", "(P * K)", (P * K));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> L_evol((P * K), (P * K));
            stan::math::initialize(L_evol, DUMMY_VAR__);
            stan::math::fill(L_evol, DUMMY_VAR__);
            stan::math::assign(L_evol,diag_pre_multiply(sigma, theta_vec_cholesky_matrix));
            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning
            current_statement_begin__ = 676;
            size_t L_j_1_max__ = K;
            size_t L_j_2_max__ = K;
            for (size_t j_1__ = 0; j_1__ < L_j_1_max__; ++j_1__) {
                for (size_t j_2__ = 0; j_2__ < L_j_2_max__; ++j_2__) {
                    if (stan::math::is_uninitialized(L(j_1__, j_2__))) {
                        std::stringstream msg__;
                        msg__ << "Undefined transformed parameter: L" << "(" << j_1__ << ", " << j_2__ << ")";
                        stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable L: ") + msg__.str()), current_statement_begin__, prog_reader__());
                    }
                }
            }
            current_statement_begin__ = 677;
            size_t L_evol_j_1_max__ = (P * K);
            size_t L_evol_j_2_max__ = (P * K);
            for (size_t j_1__ = 0; j_1__ < L_evol_j_1_max__; ++j_1__) {
                for (size_t j_2__ = 0; j_2__ < L_evol_j_2_max__; ++j_2__) {
                    if (stan::math::is_uninitialized(L_evol(j_1__, j_2__))) {
                        std::stringstream msg__;
                        msg__ << "Undefined transformed parameter: L_evol" << "(" << j_1__ << ", " << j_2__ << ")";
                        stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable L_evol: ") + msg__.str()), current_statement_begin__, prog_reader__());
                    }
                }
            }
            // model body
            {
            current_statement_begin__ = 686;
            validate_non_negative_index("mu", "K", K);
            validate_non_negative_index("mu", "T0", T0);
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > mu(T0, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(K));
            stan::math::initialize(mu, DUMMY_VAR__);
            stan::math::fill(mu, DUMMY_VAR__);
            current_statement_begin__ = 687;
            lp_accum__.add(cauchy_log<propto__>(tau, 0, obs_scale));
            current_statement_begin__ = 688;
            lp_accum__.add(cauchy_log<propto__>(sigma, 0, evol_scale));
            current_statement_begin__ = 689;
            lp_accum__.add(lkj_corr_cholesky_log<propto__>(sigma_entry_cholesky, eta_obs));
            current_statement_begin__ = 692;
            for (int t = 1; t <= T0; ++t) {
                current_statement_begin__ = 694;
                if (as_bool(force_positive)) {
                    current_statement_begin__ = 695;
                    stan::model::assign(mu, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                relu(multiply(transpose(to_matrix(get_base1(theta_vec, t, "theta_vec", 1), P, K)), get_base1(X_before, t, "X_before", 1)), pstream__), 
                                "assigning variable mu");
                } else {
                    current_statement_begin__ = 697;
                    stan::model::assign(mu, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                multiply(transpose(to_matrix(get_base1(theta_vec, t, "theta_vec", 1), P, K)), get_base1(X_before, t, "X_before", 1)), 
                                "assigning variable mu");
                }
            }
            current_statement_begin__ = 702;
            lp_accum__.add(lkj_corr_cholesky_log<propto__>(theta_vec_cholesky_matrix, eta_evol));
            current_statement_begin__ = 705;
            lp_accum__.add(multi_normal_cholesky_log<propto__>(get_base1(theta_vec, 1, "theta_vec", 1), rep_vector(0, (K * P)), L_evol));
            current_statement_begin__ = 706;
            lp_accum__.add(multi_normal_cholesky_log<propto__>(stan::model::rvalue(theta_vec, stan::model::cons_list(stan::model::index_min_max(2, T0), stan::model::nil_index_list()), "theta_vec"), stan::model::rvalue(theta_vec, stan::model::cons_list(stan::model::index_min_max(1, (T0 - 1)), stan::model::nil_index_list()), "theta_vec"), L_evol));
            current_statement_begin__ = 709;
            if (as_bool(force_positive)) {
                current_statement_begin__ = 710;
                for (int i = 1; i <= T0; ++i) {
                    current_statement_begin__ = 711;
                    lp_accum__.add(stan::math::log(get_base1(cholesky_truncate_normal_base(get_base1(Y_fit_before, i, "Y_fit_before", 1), L, lb, s, u, pstream__), 2, "cholesky_truncate_normal_base(get_base1(Y_fit_before, i, \"Y_fit_before\", 1), L, lb, s, u, pstream__)", 1)));
                    current_statement_begin__ = 712;
                    lp_accum__.add(multi_normal_cholesky_log(get_base1(Y_fit_before, i, "Y_fit_before", 1), mu, L));
                }
            } else {
                current_statement_begin__ = 717;
                lp_accum__.add(multi_normal_cholesky_log<propto__>(Y_fit_before, mu, L));
            }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
        lp_accum__.add(lp__);
        return lp_accum__.sum();
    } // log_prob()
    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }
    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("sigma_entry_cholesky");
        names__.push_back("tau");
        names__.push_back("sigma");
        names__.push_back("theta_vec");
        names__.push_back("theta_vec_cholesky_matrix");
        names__.push_back("u");
        names__.push_back("L");
        names__.push_back("L_evol");
        names__.push_back("scaled_Y_pred");
        names__.push_back("Y_pred");
        names__.push_back("theta_vec_pred");
        names__.push_back("mu_pred");
        names__.push_back("difference");
        names__.push_back("cumsum_difference");
        names__.push_back("cumsum_only_after");
        names__.push_back("arco_only_after");
        names__.push_back("arco_only_after_aggregated");
    }
    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(K);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((P * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T0);
        dims__.push_back((P * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((P * K));
        dims__.push_back((P * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((P * K));
        dims__.push_back((P * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back((K * P));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dimss__.push_back(dims__);
    }
    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        typedef double local_scalar_t__;
        vars__.resize(0);
        stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
        static const char* function__ = "model_vector_model_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_cholesky = in__.cholesky_factor_cov_constrain(K, K);
        size_t sigma_entry_cholesky_j_2_max__ = K;
        size_t sigma_entry_cholesky_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_cholesky_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_cholesky_j_1_max__; ++j_1__) {
                vars__.push_back(sigma_entry_cholesky(j_1__, j_2__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, 1> tau = in__.vector_lb_constrain(0, K);
        size_t tau_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            vars__.push_back(tau(j_1__));
        }
        Eigen::Matrix<double, Eigen::Dynamic, 1> sigma = in__.vector_lb_constrain(0, (P * K));
        size_t sigma_j_1_max__ = (P * K);
        for (size_t j_1__ = 0; j_1__ < sigma_j_1_max__; ++j_1__) {
            vars__.push_back(sigma(j_1__));
        }
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > theta_vec;
        size_t theta_vec_d_0_max__ = T0;
        theta_vec.reserve(theta_vec_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < theta_vec_d_0_max__; ++d_0__) {
            theta_vec.push_back(in__.vector_constrain((P * K)));
        }
        size_t theta_vec_j_1_max__ = (P * K);
        size_t theta_vec_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_vec_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_k_0_max__; ++k_0__) {
                vars__.push_back(theta_vec[k_0__](j_1__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> theta_vec_cholesky_matrix = in__.cholesky_factor_cov_constrain((P * K), (P * K));
        size_t theta_vec_cholesky_matrix_j_2_max__ = (P * K);
        size_t theta_vec_cholesky_matrix_j_1_max__ = (P * K);
        for (size_t j_2__ = 0; j_2__ < theta_vec_cholesky_matrix_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < theta_vec_cholesky_matrix_j_1_max__; ++j_1__) {
                vars__.push_back(theta_vec_cholesky_matrix(j_1__, j_2__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, 1> u = in__.vector_lub_constrain(0, 1, K);
        size_t u_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < u_j_1_max__; ++j_1__) {
            vars__.push_back(u(j_1__));
        }
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
        if (!include_tparams__ && !include_gqs__) return;
        try {
            // declare and define transformed parameters
            current_statement_begin__ = 676;
            validate_non_negative_index("L", "K", K);
            validate_non_negative_index("L", "K", K);
            Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> L(K, K);
            stan::math::initialize(L, DUMMY_VAR__);
            stan::math::fill(L, DUMMY_VAR__);
            stan::math::assign(L,diag_pre_multiply(tau, sigma_entry_cholesky));
            current_statement_begin__ = 677;
            validate_non_negative_index("L_evol", "(P * K)", (P * K));
            validate_non_negative_index("L_evol", "(P * K)", (P * K));
            Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> L_evol((P * K), (P * K));
            stan::math::initialize(L_evol, DUMMY_VAR__);
            stan::math::fill(L_evol, DUMMY_VAR__);
            stan::math::assign(L_evol,diag_pre_multiply(sigma, theta_vec_cholesky_matrix));
            if (!include_gqs__ && !include_tparams__) return;
            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning
            // write transformed parameters
            if (include_tparams__) {
                size_t L_j_2_max__ = K;
                size_t L_j_1_max__ = K;
                for (size_t j_2__ = 0; j_2__ < L_j_2_max__; ++j_2__) {
                    for (size_t j_1__ = 0; j_1__ < L_j_1_max__; ++j_1__) {
                        vars__.push_back(L(j_1__, j_2__));
                    }
                }
                size_t L_evol_j_2_max__ = (P * K);
                size_t L_evol_j_1_max__ = (P * K);
                for (size_t j_2__ = 0; j_2__ < L_evol_j_2_max__; ++j_2__) {
                    for (size_t j_1__ = 0; j_1__ < L_evol_j_1_max__; ++j_1__) {
                        vars__.push_back(L_evol(j_1__, j_2__));
                    }
                }
            }
            if (!include_gqs__) return;
            // declare and define generated quantities
            current_statement_begin__ = 725;
            validate_non_negative_index("scaled_Y_pred", "K", K);
            validate_non_negative_index("scaled_Y_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > scaled_Y_pred(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(scaled_Y_pred, DUMMY_VAR__);
            stan::math::fill(scaled_Y_pred, DUMMY_VAR__);
            current_statement_begin__ = 726;
            validate_non_negative_index("Y_pred", "K", K);
            validate_non_negative_index("Y_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > Y_pred(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(Y_pred, DUMMY_VAR__);
            stan::math::fill(Y_pred, DUMMY_VAR__);
            current_statement_begin__ = 727;
            validate_non_negative_index("theta_vec_pred", "(K * P)", (K * P));
            validate_non_negative_index("theta_vec_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > theta_vec_pred(T, Eigen::Matrix<double, Eigen::Dynamic, 1>((K * P)));
            stan::math::initialize(theta_vec_pred, DUMMY_VAR__);
            stan::math::fill(theta_vec_pred, DUMMY_VAR__);
            current_statement_begin__ = 728;
            validate_non_negative_index("mu_pred", "K", K);
            validate_non_negative_index("mu_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mu_pred(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(mu_pred, DUMMY_VAR__);
            stan::math::fill(mu_pred, DUMMY_VAR__);
            current_statement_begin__ = 730;
            validate_non_negative_index("difference", "K", K);
            validate_non_negative_index("difference", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > difference(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(difference, DUMMY_VAR__);
            stan::math::fill(difference, DUMMY_VAR__);
            current_statement_begin__ = 731;
            validate_non_negative_index("cumsum_difference", "K", K);
            validate_non_negative_index("cumsum_difference", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > cumsum_difference(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(cumsum_difference, DUMMY_VAR__);
            stan::math::fill(cumsum_difference, DUMMY_VAR__);
            current_statement_begin__ = 732;
            validate_non_negative_index("cumsum_only_after", "K", K);
            validate_non_negative_index("cumsum_only_after", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > cumsum_only_after(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(cumsum_only_after, DUMMY_VAR__);
            stan::math::fill(cumsum_only_after, DUMMY_VAR__);
            current_statement_begin__ = 733;
            validate_non_negative_index("arco_only_after", "K", K);
            validate_non_negative_index("arco_only_after", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > arco_only_after(T, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
            stan::math::initialize(arco_only_after, DUMMY_VAR__);
            stan::math::fill(arco_only_after, DUMMY_VAR__);
            current_statement_begin__ = 734;
            validate_non_negative_index("arco_only_after_aggregated", "T", T);
            Eigen::Matrix<double, Eigen::Dynamic, 1> arco_only_after_aggregated(T);
            stan::math::initialize(arco_only_after_aggregated, DUMMY_VAR__);
            stan::math::fill(arco_only_after_aggregated, DUMMY_VAR__);
            // generated quantities statements
            current_statement_begin__ = 740;
            stan::model::assign(theta_vec_pred, 
                        stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), 
                        theta_vec, 
                        "assigning variable theta_vec_pred");
            current_statement_begin__ = 742;
            for (int t = (T0 + 1); t <= T; ++t) {
                current_statement_begin__ = 743;
                stan::model::assign(theta_vec_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            get_base1(theta_vec, T0, "theta_vec", 1), 
                            "assigning variable theta_vec_pred");
            }
            current_statement_begin__ = 746;
            for (int t = 1; t <= T; ++t) {
                current_statement_begin__ = 748;
                if (as_bool(force_positive)) {
                    current_statement_begin__ = 749;
                    stan::model::assign(mu_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                relu(multiply(transpose(to_matrix(get_base1(theta_vec_pred, t, "theta_vec_pred", 1), P, K)), get_base1(X_fit, t, "X_fit", 1)), pstream__), 
                                "assigning variable mu_pred");
                } else {
                    current_statement_begin__ = 752;
                    stan::model::assign(mu_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                multiply(transpose(to_matrix(get_base1(theta_vec_pred, t, "theta_vec_pred", 1), P, K)), get_base1(X_fit, t, "X_fit", 1)), 
                                "assigning variable mu_pred");
                }
            }
            current_statement_begin__ = 758;
            if (as_bool(force_positive)) {
                current_statement_begin__ = 760;
                for (int t = 1; t <= T; ++t) {
                    current_statement_begin__ = 761;
                    stan::model::assign(scaled_Y_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                add(get_base1(mu_pred, t, "mu_pred", 1), multiply(L, get_base1(cholesky_truncate_normal_base(get_base1(mu_pred, t, "mu_pred", 1), L, lb, s, u, pstream__), 1, "cholesky_truncate_normal_base(get_base1(mu_pred, t, \"mu_pred\", 1), L, lb, s, u, pstream__)", 1))), 
                                "assigning variable scaled_Y_pred");
                }
            } else {
                current_statement_begin__ = 767;
                stan::math::assign(scaled_Y_pred, multi_normal_cholesky_rng(mu_pred, sigma_entry_cholesky, base_rng__));
            }
            current_statement_begin__ = 772;
            if (as_bool(scale)) {
                current_statement_begin__ = 774;
                stan::math::assign(Y_pred, unscale_vector_array(scaled_Y_pred, Y, use_log, pstream__));
            } else {
                current_statement_begin__ = 776;
                if (as_bool(use_log)) {
                    current_statement_begin__ = 777;
                    stan::math::assign(Y_pred, stan::math::exp(scaled_Y_pred));
                } else {
                    current_statement_begin__ = 779;
                    stan::math::assign(Y_pred, scaled_Y_pred);
                }
            }
            current_statement_begin__ = 784;
            for (int t = 1; t <= T; ++t) {
                current_statement_begin__ = 785;
                stan::model::assign(difference, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            subtract(get_base1(Y, t, "Y", 1), get_base1(Y_pred, t, "Y_pred", 1)), 
                            "assigning variable difference");
            }
            current_statement_begin__ = 788;
            stan::model::assign(cumsum_only_after, 
                        stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), 
                        rep_array(rep_vector(0, K), T0), 
                        "assigning variable cumsum_only_after");
            current_statement_begin__ = 789;
            stan::model::assign(cumsum_only_after, 
                        stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), 
                        cumsum_vector(stan::model::rvalue(difference, stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "difference"), pstream__), 
                        "assigning variable cumsum_only_after");
            current_statement_begin__ = 791;
            stan::math::assign(cumsum_difference, cumsum_vector(difference, pstream__));
            current_statement_begin__ = 793;
            stan::model::assign(arco_only_after, 
                        stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), 
                        rep_array(rep_vector(0, K), T0), 
                        "assigning variable arco_only_after");
            current_statement_begin__ = 794;
            stan::model::assign(arco_only_after_aggregated, 
                        stan::model::cons_list(stan::model::index_min_max(1, T0), stan::model::nil_index_list()), 
                        rep_vector(0, T0), 
                        "assigning variable arco_only_after_aggregated");
            current_statement_begin__ = 797;
            for (int t = (T0 + 1); t <= T; ++t) {
                current_statement_begin__ = 798;
                stan::model::assign(arco_only_after, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            multiply((1.0 / (t - T0)), get_base1(cumsum_only_after, t, "cumsum_only_after", 1)), 
                            "assigning variable arco_only_after");
                current_statement_begin__ = 799;
                stan::model::assign(arco_only_after_aggregated, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            mean(get_base1(arco_only_after, t, "arco_only_after", 1)), 
                            "assigning variable arco_only_after_aggregated");
            }
            // validate, write generated quantities
            current_statement_begin__ = 725;
            size_t scaled_Y_pred_j_1_max__ = K;
            size_t scaled_Y_pred_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                    vars__.push_back(scaled_Y_pred[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 726;
            size_t Y_pred_j_1_max__ = K;
            size_t Y_pred_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                    vars__.push_back(Y_pred[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 727;
            size_t theta_vec_pred_j_1_max__ = (K * P);
            size_t theta_vec_pred_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < theta_vec_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < theta_vec_pred_k_0_max__; ++k_0__) {
                    vars__.push_back(theta_vec_pred[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 728;
            size_t mu_pred_j_1_max__ = K;
            size_t mu_pred_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                    vars__.push_back(mu_pred[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 730;
            size_t difference_j_1_max__ = K;
            size_t difference_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                    vars__.push_back(difference[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 731;
            size_t cumsum_difference_j_1_max__ = K;
            size_t cumsum_difference_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                    vars__.push_back(cumsum_difference[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 732;
            size_t cumsum_only_after_j_1_max__ = K;
            size_t cumsum_only_after_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                    vars__.push_back(cumsum_only_after[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 733;
            size_t arco_only_after_j_1_max__ = K;
            size_t arco_only_after_k_0_max__ = T;
            for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                    vars__.push_back(arco_only_after[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 734;
            size_t arco_only_after_aggregated_j_1_max__ = T;
            for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
                vars__.push_back(arco_only_after_aggregated(j_1__));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }
    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng, params_r_vec, params_i_vec, vars_vec, include_tparams, include_gqs, pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }
    std::string model_name() const {
        return "model_vector_model";
    }
    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t sigma_entry_cholesky_j_2_max__ = K;
        size_t sigma_entry_cholesky_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_cholesky_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_cholesky_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "sigma_entry_cholesky" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t tau_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t sigma_j_1_max__ = (P * K);
        for (size_t j_1__ = 0; j_1__ < sigma_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_vec_j_1_max__ = (P * K);
        size_t theta_vec_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_vec_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_vec" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t theta_vec_cholesky_matrix_j_2_max__ = (P * K);
        size_t theta_vec_cholesky_matrix_j_1_max__ = (P * K);
        for (size_t j_2__ = 0; j_2__ < theta_vec_cholesky_matrix_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < theta_vec_cholesky_matrix_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_vec_cholesky_matrix" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t u_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < u_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "u" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        if (!include_gqs__ && !include_tparams__) return;
        if (include_tparams__) {
            size_t L_j_2_max__ = K;
            size_t L_j_1_max__ = K;
            for (size_t j_2__ = 0; j_2__ < L_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < L_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "L" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t L_evol_j_2_max__ = (P * K);
            size_t L_evol_j_1_max__ = (P * K);
            for (size_t j_2__ = 0; j_2__ < L_evol_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < L_evol_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "L_evol" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        if (!include_gqs__) return;
        size_t scaled_Y_pred_j_1_max__ = K;
        size_t scaled_Y_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "scaled_Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t Y_pred_j_1_max__ = K;
        size_t Y_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t theta_vec_pred_j_1_max__ = (K * P);
        size_t theta_vec_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < theta_vec_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_vec_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t mu_pred_j_1_max__ = K;
        size_t mu_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mu_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t difference_j_1_max__ = K;
        size_t difference_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t cumsum_difference_j_1_max__ = K;
        size_t cumsum_difference_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "cumsum_difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t cumsum_only_after_j_1_max__ = K;
        size_t cumsum_only_after_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "cumsum_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t arco_only_after_j_1_max__ = K;
        size_t arco_only_after_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "arco_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t arco_only_after_aggregated_j_1_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "arco_only_after_aggregated" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
    }
    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t sigma_entry_cholesky_j_1_max__ = (((K * (K + 1)) / 2) + ((K - K) * K));
        for (size_t j_1__ = 0; j_1__ < sigma_entry_cholesky_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma_entry_cholesky" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t tau_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t sigma_j_1_max__ = (P * K);
        for (size_t j_1__ = 0; j_1__ < sigma_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_vec_j_1_max__ = (P * K);
        size_t theta_vec_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_vec_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_vec" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t theta_vec_cholesky_matrix_j_1_max__ = ((((P * K) * ((P * K) + 1)) / 2) + (((P * K) - (P * K)) * (P * K)));
        for (size_t j_1__ = 0; j_1__ < theta_vec_cholesky_matrix_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_vec_cholesky_matrix" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t u_j_1_max__ = K;
        for (size_t j_1__ = 0; j_1__ < u_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "u" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        if (!include_gqs__ && !include_tparams__) return;
        if (include_tparams__) {
            size_t L_j_2_max__ = K;
            size_t L_j_1_max__ = K;
            for (size_t j_2__ = 0; j_2__ < L_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < L_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "L" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t L_evol_j_2_max__ = (P * K);
            size_t L_evol_j_1_max__ = (P * K);
            for (size_t j_2__ = 0; j_2__ < L_evol_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < L_evol_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "L_evol" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        if (!include_gqs__) return;
        size_t scaled_Y_pred_j_1_max__ = K;
        size_t scaled_Y_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "scaled_Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t Y_pred_j_1_max__ = K;
        size_t Y_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t theta_vec_pred_j_1_max__ = (K * P);
        size_t theta_vec_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < theta_vec_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_vec_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_vec_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t mu_pred_j_1_max__ = K;
        size_t mu_pred_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mu_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t difference_j_1_max__ = K;
        size_t difference_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t cumsum_difference_j_1_max__ = K;
        size_t cumsum_difference_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "cumsum_difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t cumsum_only_after_j_1_max__ = K;
        size_t cumsum_only_after_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "cumsum_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t arco_only_after_j_1_max__ = K;
        size_t arco_only_after_k_0_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "arco_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t arco_only_after_aggregated_j_1_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "arco_only_after_aggregated" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
    }
}; // model
}  // namespace
typedef model_vector_model_namespace::model_vector_model stan_model;
#ifndef USING_R
stan::model::model_base& new_model(
        stan::io::var_context& data_context,
        unsigned int seed,
        std::ostream* msg_stream) {
  stan_model* m = new stan_model(data_context, seed, msg_stream);
  return *m;
}
#endif
#endif
