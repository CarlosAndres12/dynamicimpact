// Generated by rstantools.  Do not edit by hand.

/*
    dynamicimpact is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    dynamicimpact is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with dynamicimpact.  If not, see <http://www.gnu.org/licenses/>.
*/
#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.21.0
#include <stan/model/model_header.hpp>
namespace model_matrix_model_namespace {
using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;
static int current_statement_begin__;
stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_matrix_model");
    reader.add_event(0, 0, "include", "include/utils.stan");
    reader.add_event(0, 0, "start", "include/utils.stan");
    reader.add_event(555, 555, "end", "include/utils.stan");
    reader.add_event(555, 1, "restart", "model_matrix_model");
    reader.add_event(799, 243, "end", "model_matrix_model");
    return reader;
}
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
relu(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 5;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 7;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 11;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 13;
            if (as_bool(logical_gt(get_base1(input, i, "input", 1), 0))) {
                current_statement_begin__ = 14;
                stan::model::assign(result, 
                            stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                            get_base1(input, i, "input", 1), 
                            "assigning variable result");
            } else {
                current_statement_begin__ = 16;
                stan::model::assign(result, 
                            stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                            0, 
                            "assigning variable result");
            }
        }
        current_statement_begin__ = 21;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct relu_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) const {
        return relu(input, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic, 1> >
cholesky_truncate_normal_base(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& mu,
                                  const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                  const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& b,
                                  const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& s,
                                  const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& u, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 28;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(mu));
        current_statement_begin__ = 28;
        validate_non_negative_index("d", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> d(K);
        stan::math::initialize(d, DUMMY_VAR__);
        stan::math::fill(d, DUMMY_VAR__);
        current_statement_begin__ = 28;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 28;
        validate_non_negative_index("out", "K", K);
        validate_non_negative_index("out", "2", 2);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > out(2, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(K));
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);
        current_statement_begin__ = 29;
        for (int k = 1; k <= K; ++k) {
            {
            current_statement_begin__ = 30;
            int km1(0);
            (void) km1;  // dummy to suppress unused var warning
            stan::math::fill(km1, std::numeric_limits<int>::min());
            stan::math::assign(km1,(k - 1));
            current_statement_begin__ = 31;
            if (as_bool(logical_neq(get_base1(s, k, "s", 1), 0))) {
                {
                current_statement_begin__ = 32;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                stan::math::assign(z_star,((get_base1(b, k, "b", 1) - (get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) ))) / get_base1(L, k, k, "L", 1)));
                current_statement_begin__ = 35;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 35;
                local_scalar_t__ u_star(DUMMY_VAR__);
                (void) u_star;  // dummy to suppress unused var warning
                stan::math::initialize(u_star, DUMMY_VAR__);
                stan::math::fill(u_star, DUMMY_VAR__);
                stan::math::assign(u_star,Phi(z_star));
                current_statement_begin__ = 36;
                if (as_bool(logical_eq(get_base1(s, k, "s", 1), -(1)))) {
                    current_statement_begin__ = 37;
                    stan::math::assign(v, (u_star * get_base1(u, k, "u", 1)));
                    current_statement_begin__ = 38;
                    stan::model::assign(d, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                u_star, 
                                "assigning variable d");
                } else {
                    current_statement_begin__ = 41;
                    stan::model::assign(d, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (1 - u_star), 
                                "assigning variable d");
                    current_statement_begin__ = 42;
                    stan::math::assign(v, (u_star + (get_base1(d, k, "d", 1) * get_base1(u, k, "u", 1))));
                }
                current_statement_begin__ = 44;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                }
            } else {
                current_statement_begin__ = 47;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
                current_statement_begin__ = 48;
                stan::model::assign(d, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            1, 
                            "assigning variable d");
            }
            }
        }
        current_statement_begin__ = 51;
        stan::model::assign(out, 
                    stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                    z, 
                    "assigning variable out");
        current_statement_begin__ = 52;
        stan::model::assign(out, 
                    stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                    d, 
                    "assigning variable out");
        current_statement_begin__ = 53;
        return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cholesky_truncate_normal_base_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic, 1> >
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& mu,
                                  const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                  const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& b,
                                  const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& s,
                                  const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& u, std::ostream* pstream__) const {
        return cholesky_truncate_normal_base(mu, L, b, s, u, pstream__);
    }
};
template <bool propto, typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
multi_normal_cholesky_truncated_lpdf(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 59;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 60;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 61;
        local_scalar_t__ lp(DUMMY_VAR__);
        (void) lp;  // dummy to suppress unused var warning
        stan::math::initialize(lp, DUMMY_VAR__);
        stan::math::fill(lp, DUMMY_VAR__);
        stan::math::assign(lp,0);
        current_statement_begin__ = 63;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 66;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 67;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 69;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 70;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 71;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 72;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 73;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 74;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 77;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 78;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 79;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 80;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 83;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 84;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 85;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                current_statement_begin__ = 86;
                stan::math::assign(lp, (lp + logd));
                }
            }
        }
        current_statement_begin__ = 89;
        return stan::math::promote_scalar<fun_return_scalar_t__>(lp);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
multi_normal_cholesky_truncated_lpdf(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) {
    return multi_normal_cholesky_truncated_lpdf<false>(u,mu,L,lb,ub,lb_ind,ub_ind, pstream__);
}
struct multi_normal_cholesky_truncated_lpdf_functor__ {
    template <bool propto, typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                         const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                         const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                         const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                         const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                         const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_lpdf(u, mu, L, lb, ub, lb_ind, ub_ind, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, class RNG>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type, Eigen::Dynamic, 1>
multi_normal_cholesky_truncated_rng(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                        const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                        const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                        const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                        const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                        const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                        const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 95;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 96;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 98;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 101;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 102;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 104;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 105;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 106;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 107;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 108;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 109;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 112;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 113;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 114;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 115;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 118;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 119;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 120;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                }
            }
        }
        current_statement_begin__ = 123;
        return stan::math::promote_scalar<fun_return_scalar_t__>(add(mu, multiply(L, z)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct multi_normal_cholesky_truncated_rng_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, class RNG>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                        const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                        const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                        const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                        const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                        const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                        const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, RNG& base_rng__, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_rng(u, mu, L, lb, ub, lb_ind, ub_ind, base_rng__, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T_lp__, typename T_lp_accum__>
void
multi_normal_cholesky_truncated_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                       const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                       const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                       const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                       const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T_lp__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 129;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(u));
        current_statement_begin__ = 130;
        validate_non_negative_index("z", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z(K);
        stan::math::initialize(z, DUMMY_VAR__);
        stan::math::fill(z, DUMMY_VAR__);
        current_statement_begin__ = 132;
        for (int k = 1; k <= K; ++k) {
            current_statement_begin__ = 135;
            if (as_bool((primitive_value(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 0)) && primitive_value(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 0))))) {
                current_statement_begin__ = 136;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(get_base1(u, k, "u", 1)), 
                            "assigning variable z");
            } else {
                {
                current_statement_begin__ = 138;
                int km1(0);
                (void) km1;  // dummy to suppress unused var warning
                stan::math::fill(km1, std::numeric_limits<int>::min());
                stan::math::assign(km1,(k - 1));
                current_statement_begin__ = 139;
                local_scalar_t__ v(DUMMY_VAR__);
                (void) v;  // dummy to suppress unused var warning
                stan::math::initialize(v, DUMMY_VAR__);
                stan::math::fill(v, DUMMY_VAR__);
                current_statement_begin__ = 140;
                local_scalar_t__ z_star(DUMMY_VAR__);
                (void) z_star;  // dummy to suppress unused var warning
                stan::math::initialize(z_star, DUMMY_VAR__);
                stan::math::fill(z_star, DUMMY_VAR__);
                current_statement_begin__ = 141;
                local_scalar_t__ logd(DUMMY_VAR__);
                (void) logd;  // dummy to suppress unused var warning
                stan::math::initialize(logd, DUMMY_VAR__);
                stan::math::fill(logd, DUMMY_VAR__);
                current_statement_begin__ = 142;
                validate_non_negative_index("log_ustar", "2", 2);
                Eigen::Matrix<local_scalar_t__, 1, Eigen::Dynamic> log_ustar(2);
                stan::math::initialize(log_ustar, DUMMY_VAR__);
                stan::math::fill(log_ustar, DUMMY_VAR__);
                stan::math::assign(log_ustar,stan::math::to_row_vector(stan::math::array_builder<local_scalar_t__ >().add(stan::math::negative_infinity()).add(0).array()));
                current_statement_begin__ = 143;
                local_scalar_t__ constrain(DUMMY_VAR__);
                (void) constrain;  // dummy to suppress unused var warning
                stan::math::initialize(constrain, DUMMY_VAR__);
                stan::math::fill(constrain, DUMMY_VAR__);
                stan::math::assign(constrain,(get_base1(mu, k, "mu", 1) + (logical_gt(k, 1) ? stan::math::promote_scalar<local_scalar_t__>(multiply(stan::model::rvalue(L, stan::model::cons_list(stan::model::index_uni(k), stan::model::cons_list(stan::model::index_min_max(1, km1), stan::model::nil_index_list())), "L"), head(z, km1))) : stan::math::promote_scalar<local_scalar_t__>(0) )));
                current_statement_begin__ = 146;
                if (as_bool(logical_eq(get_base1(lb_ind, k, "lb_ind", 1), 1))) {
                    current_statement_begin__ = 147;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(lb, k, "lb", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 148;
                if (as_bool(logical_eq(get_base1(ub_ind, k, "ub_ind", 1), 1))) {
                    current_statement_begin__ = 149;
                    stan::model::assign(log_ustar, 
                                stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list()), 
                                normal_cdf_log(((get_base1(ub, k, "ub", 1) - constrain) / get_base1(L, k, k, "L", 1)), 0.0, 1.0), 
                                "assigning variable log_ustar");
                }
                current_statement_begin__ = 152;
                stan::math::assign(logd, log_diff_exp(get_base1(log_ustar, 2, "log_ustar", 1), get_base1(log_ustar, 1, "log_ustar", 1)));
                current_statement_begin__ = 153;
                stan::math::assign(v, stan::math::exp(log_sum_exp(get_base1(log_ustar, 1, "log_ustar", 1), (stan::math::log(get_base1(u, k, "u", 1)) + logd))));
                current_statement_begin__ = 154;
                stan::model::assign(z, 
                            stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                            inv_Phi(v), 
                            "assigning variable z");
                current_statement_begin__ = 155;
                lp_accum__.add(logd);
                }
            }
        }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct multi_normal_cholesky_truncated_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& u,
                                       const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                                       const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& L,
                                       const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& lb,
                                       const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& ub,
                                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& lb_ind,
                                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& ub_ind, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return multi_normal_cholesky_truncated_lp(u, mu, L, lb, ub, lb_ind, ub_ind, lp__, lp_accum__, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, class RNG>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
truncate_multi_normal_rng(const T0__& lowerbound,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& Sigma, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 175;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(mu), 1, "dims(mu)", 1));
        current_statement_begin__ = 177;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 179;
        stan::math::assign(result, multi_normal_rng(mu, Sigma, base_rng__));
        current_statement_begin__ = 181;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct truncate_multi_normal_rng_functor__ {
    template <typename T0__, typename T1__, typename T2__, class RNG>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
    operator()(const T0__& lowerbound,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& mu,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& Sigma, RNG& base_rng__, std::ostream* pstream__) const {
        return truncate_multi_normal_rng(lowerbound, mu, Sigma, base_rng__, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
pow_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& powers, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 187;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 189;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 191;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 192;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        pow(get_base1(input, i, "input", 1), get_base1(powers, i, "powers", 1)), 
                        "assigning variable result");
        }
        current_statement_begin__ = 195;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct pow_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& powers, std::ostream* pstream__) const {
        return pow_vector(input, powers, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
abs_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 201;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 203;
        validate_non_negative_index("result", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result(N_SIZE);
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 205;
        for (int i = 1; i <= N_SIZE; ++i) {
            current_statement_begin__ = 206;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        stan::math::fabs(get_base1(input, i, "input", 1)), 
                        "assigning variable result");
        }
        current_statement_begin__ = 209;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct abs_vector_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input, std::ostream* pstream__) const {
        return abs_vector(input, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
vector_abs(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 215;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input), 1, "dims(input)", 1));
        current_statement_begin__ = 216;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input), 2, "dims(input)", 1));
        current_statement_begin__ = 218;
        validate_non_negative_index("result", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 220;
        for (int i = 1; i <= ARRAY_LENGTH; ++i) {
            current_statement_begin__ = 221;
            stan::model::assign(result, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        abs_vector(get_base1(input, i, "input", 1), pstream__), 
                        "assigning variable result");
        }
        current_statement_begin__ = 224;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct vector_abs_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input, std::ostream* pstream__) const {
        return vector_abs(input, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__>
typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
elastic_net_regularizaion_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& params,
                                     const T1__& alpha1,
                                     const T2__& alpha2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 230;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(params), 1, "dims(params)", 1));
        current_statement_begin__ = 232;
        local_scalar_t__ result(DUMMY_VAR__);
        (void) result;  // dummy to suppress unused var warning
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        current_statement_begin__ = 234;
        local_scalar_t__ squere_part(DUMMY_VAR__);
        (void) squere_part;  // dummy to suppress unused var warning
        stan::math::initialize(squere_part, DUMMY_VAR__);
        stan::math::fill(squere_part, DUMMY_VAR__);
        stan::math::assign(squere_part,(alpha1 * sum(pow_vector(params, rep_vector(2.0, N_SIZE), pstream__))));
        current_statement_begin__ = 236;
        local_scalar_t__ abs_part(DUMMY_VAR__);
        (void) abs_part;  // dummy to suppress unused var warning
        stan::math::initialize(abs_part, DUMMY_VAR__);
        stan::math::fill(abs_part, DUMMY_VAR__);
        stan::math::assign(abs_part,(alpha2 * sum(abs_vector(params, pstream__))));
        current_statement_begin__ = 238;
        stan::math::assign(result, (squere_part + abs_part));
        current_statement_begin__ = 240;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct elastic_net_regularizaion_vector_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& params,
                                     const T1__& alpha1,
                                     const T2__& alpha2, std::ostream* pstream__) const {
        return elastic_net_regularizaion_vector(params, alpha1, alpha2, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__>
typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
elastic_net_regularizaion(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& params,
                              const T1__& alpha1,
                              const T2__& alpha2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 246;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(params), 1, "dims(params)", 1));
        current_statement_begin__ = 247;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(params), 2, "dims(params)", 1));
        current_statement_begin__ = 249;
        local_scalar_t__ result(DUMMY_VAR__);
        (void) result;  // dummy to suppress unused var warning
        stan::math::initialize(result, DUMMY_VAR__);
        stan::math::fill(result, DUMMY_VAR__);
        stan::math::assign(result,0);
        current_statement_begin__ = 251;
        for (int j = 1; j <= VECTOR_LENGTH; ++j) {
            current_statement_begin__ = 253;
            stan::math::assign(result, (result + elastic_net_regularizaion_vector(to_vector(stan::model::rvalue(params, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "params")), alpha1, alpha2, pstream__)));
        }
        current_statement_begin__ = 257;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct elastic_net_regularizaion_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& params,
                              const T1__& alpha1,
                              const T2__& alpha2, std::ostream* pstream__) const {
        return elastic_net_regularizaion(params, alpha1, alpha2, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
kronecker_prod(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& A,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& B, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 265;
        validate_non_negative_index("C", "(rows(A) * rows(B))", (rows(A) * rows(B)));
        validate_non_negative_index("C", "(cols(A) * cols(B))", (cols(A) * cols(B)));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> C((rows(A) * rows(B)), (cols(A) * cols(B)));
        stan::math::initialize(C, DUMMY_VAR__);
        stan::math::fill(C, DUMMY_VAR__);
        stan::math::assign(C,rep_matrix(0.0, (rows(A) * rows(B)), (rows(A) * rows(B))));
        current_statement_begin__ = 266;
        int m(0);
        (void) m;  // dummy to suppress unused var warning
        stan::math::fill(m, std::numeric_limits<int>::min());
        current_statement_begin__ = 267;
        int n(0);
        (void) n;  // dummy to suppress unused var warning
        stan::math::fill(n, std::numeric_limits<int>::min());
        current_statement_begin__ = 268;
        int p(0);
        (void) p;  // dummy to suppress unused var warning
        stan::math::fill(p, std::numeric_limits<int>::min());
        current_statement_begin__ = 269;
        int q(0);
        (void) q;  // dummy to suppress unused var warning
        stan::math::fill(q, std::numeric_limits<int>::min());
        current_statement_begin__ = 271;
        stan::math::assign(m, rows(A));
        current_statement_begin__ = 272;
        stan::math::assign(n, cols(A));
        current_statement_begin__ = 273;
        stan::math::assign(p, rows(B));
        current_statement_begin__ = 274;
        stan::math::assign(q, cols(B));
        current_statement_begin__ = 276;
        if (as_bool((primitive_value(logical_eq(rows(A), 1)) && primitive_value(logical_eq(cols(A), 1))))) {
            current_statement_begin__ = 277;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(A, 1, 1, "A", 1), B));
        }
        current_statement_begin__ = 280;
        if (as_bool((primitive_value(logical_eq(rows(B), 1)) && primitive_value(logical_eq(cols(B), 1))))) {
            current_statement_begin__ = 281;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(B, 1, 1, "B", 1), A));
        }
        current_statement_begin__ = 284;
        for (int i = 1; i <= m; ++i) {
            current_statement_begin__ = 286;
            for (int j = 1; j <= n; ++j) {
                {
                current_statement_begin__ = 287;
                int row_start(0);
                (void) row_start;  // dummy to suppress unused var warning
                stan::math::fill(row_start, std::numeric_limits<int>::min());
                current_statement_begin__ = 288;
                int row_end(0);
                (void) row_end;  // dummy to suppress unused var warning
                stan::math::fill(row_end, std::numeric_limits<int>::min());
                current_statement_begin__ = 289;
                int col_start(0);
                (void) col_start;  // dummy to suppress unused var warning
                stan::math::fill(col_start, std::numeric_limits<int>::min());
                current_statement_begin__ = 290;
                int col_end(0);
                (void) col_end;  // dummy to suppress unused var warning
                stan::math::fill(col_end, std::numeric_limits<int>::min());
                current_statement_begin__ = 291;
                stan::math::assign(row_start, (((i - 1) * p) + 1));
                current_statement_begin__ = 292;
                stan::math::assign(row_end, (((i - 1) * p) + p));
                current_statement_begin__ = 293;
                stan::math::assign(col_start, (((j - 1) * q) + 1));
                current_statement_begin__ = 294;
                stan::math::assign(col_end, (((j - 1) * q) + q));
                current_statement_begin__ = 295;
                stan::model::assign(C, 
                            stan::model::cons_list(stan::model::index_min_max(row_start, row_end), stan::model::cons_list(stan::model::index_min_max(col_start, col_end), stan::model::nil_index_list())), 
                            multiply(get_base1(A, i, j, "A", 1), B), 
                            "assigning variable C");
                }
            }
        }
        current_statement_begin__ = 300;
        return stan::math::promote_scalar<fun_return_scalar_t__>(C);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct kronecker_prod_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& A,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& B, std::ostream* pstream__) const {
        return kronecker_prod(A, B, pstream__);
    }
};
template <typename T0__, typename T1__, typename T2__, typename T3__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type
log_matrix_normal_density(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& y_real,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& y_est,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& V,
                              const Eigen::Matrix<T3__, Eigen::Dynamic, Eigen::Dynamic>& U, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 307;
        local_scalar_t__ det_V(DUMMY_VAR__);
        (void) det_V;  // dummy to suppress unused var warning
        stan::math::initialize(det_V, DUMMY_VAR__);
        stan::math::fill(det_V, DUMMY_VAR__);
        stan::math::assign(det_V,determinant(V));
        current_statement_begin__ = 308;
        local_scalar_t__ det_U(DUMMY_VAR__);
        (void) det_U;  // dummy to suppress unused var warning
        stan::math::initialize(det_U, DUMMY_VAR__);
        stan::math::fill(det_U, DUMMY_VAR__);
        stan::math::assign(det_U,determinant(U));
        current_statement_begin__ = 312;
        validate_non_negative_index("inv_V", "get_base1(dims(V), 1, \"dims(V)\", 1)", get_base1(dims(V), 1, "dims(V)", 1));
        validate_non_negative_index("inv_V", "get_base1(dims(V), 2, \"dims(V)\", 1)", get_base1(dims(V), 2, "dims(V)", 1));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> inv_V(get_base1(dims(V), 1, "dims(V)", 1), get_base1(dims(V), 2, "dims(V)", 1));
        stan::math::initialize(inv_V, DUMMY_VAR__);
        stan::math::fill(inv_V, DUMMY_VAR__);
        stan::math::assign(inv_V,inverse_spd(V));
        current_statement_begin__ = 313;
        validate_non_negative_index("inv_U", "get_base1(dims(U), 1, \"dims(U)\", 1)", get_base1(dims(U), 1, "dims(U)", 1));
        validate_non_negative_index("inv_U", "get_base1(dims(U), 2, \"dims(U)\", 1)", get_base1(dims(U), 2, "dims(U)", 1));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> inv_U(get_base1(dims(U), 1, "dims(U)", 1), get_base1(dims(U), 2, "dims(U)", 1));
        stan::math::initialize(inv_U, DUMMY_VAR__);
        stan::math::fill(inv_U, DUMMY_VAR__);
        stan::math::assign(inv_U,inverse_spd(U));
        current_statement_begin__ = 315;
        int n(0);
        (void) n;  // dummy to suppress unused var warning
        stan::math::fill(n, std::numeric_limits<int>::min());
        stan::math::assign(n,get_base1(dims(y_real), 1, "dims(y_real)", 1));
        current_statement_begin__ = 316;
        int p(0);
        (void) p;  // dummy to suppress unused var warning
        stan::math::fill(p, std::numeric_limits<int>::min());
        stan::math::assign(p,get_base1(dims(y_real), 2, "dims(y_real)", 1));
        current_statement_begin__ = 319;
        validate_non_negative_index("temp_matrix", "p", p);
        validate_non_negative_index("temp_matrix", "p", p);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> temp_matrix(p, p);
        stan::math::initialize(temp_matrix, DUMMY_VAR__);
        stan::math::fill(temp_matrix, DUMMY_VAR__);
        stan::math::assign(temp_matrix,multiply((-(1) / 2.0), multiply(multiply(multiply(inv_V, transpose(subtract(y_real, y_est))), inv_U), subtract(y_real, y_est))));
        current_statement_begin__ = 322;
        local_scalar_t__ result_value(DUMMY_VAR__);
        (void) result_value;  // dummy to suppress unused var warning
        stan::math::initialize(result_value, DUMMY_VAR__);
        stan::math::fill(result_value, DUMMY_VAR__);
        stan::math::assign(result_value,(((trace(temp_matrix) - stan::math::log(pow((2.0 * stan::math::pi()), (((1.0 * n) * p) / 2.0)))) - stan::math::log(pow(det_V, ((1.0 * n) / 2.0)))) - stan::math::log(pow(det_U, ((1.0 * p) / 2.0)))));
        current_statement_begin__ = 324;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_value);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct log_matrix_normal_density_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& y_real,
                              const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& y_est,
                              const Eigen::Matrix<T2__, Eigen::Dynamic, Eigen::Dynamic>& V,
                              const Eigen::Matrix<T3__, Eigen::Dynamic, Eigen::Dynamic>& U, std::ostream* pstream__) const {
        return log_matrix_normal_density(y_real, y_est, V, U, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
cumsum_matrix(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 330;
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 2, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 3, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 3, "dims(input_matrix)", 1));
        validate_non_negative_index("result_matrix", "get_base1(dims(input_matrix), 1, \"dims(input_matrix)\", 1)", get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix(get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1), Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1), get_base1(dims(input_matrix), 3, "dims(input_matrix)", 1)));
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 332;
        for (int t = 1; t <= get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1); ++t) {
            current_statement_begin__ = 334;
            if (as_bool(logical_eq(t, 1))) {
                current_statement_begin__ = 335;
                stan::model::assign(result_matrix, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            get_base1(input_matrix, t, "input_matrix", 1), 
                            "assigning variable result_matrix");
            } else {
                current_statement_begin__ = 337;
                stan::model::assign(result_matrix, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            add(get_base1(result_matrix, (t - 1), "result_matrix", 1), get_base1(input_matrix, t, "input_matrix", 1)), 
                            "assigning variable result_matrix");
            }
        }
        current_statement_begin__ = 341;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cumsum_matrix_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix, std::ostream* pstream__) const {
        return cumsum_matrix(input_matrix, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
cumsum_vector(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 347;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 349;
        validate_non_negative_index("result_vector", "get_base1(dims(input_vector), 2, \"dims(input_vector)\", 1)", get_base1(dims(input_vector), 2, "dims(input_vector)", 1));
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_vector(N_SIZE, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(get_base1(dims(input_vector), 2, "dims(input_vector)", 1)));
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 351;
        stan::model::assign(result_vector, 
                    stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                    get_base1(input_vector, 1, "input_vector", 1), 
                    "assigning variable result_vector");
        current_statement_begin__ = 353;
        for (int t = 2; t <= N_SIZE; ++t) {
            current_statement_begin__ = 354;
            stan::model::assign(result_vector, 
                        stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                        add(get_base1(result_vector, (t - 1), "result_vector", 1), get_base1(input_vector, t, "input_vector", 1)), 
                        "assigning variable result_vector");
        }
        current_statement_begin__ = 357;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cumsum_vector_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector, std::ostream* pstream__) const {
        return cumsum_vector(input_vector, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
scale_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                 const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 362;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 364;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result_vector(N_SIZE);
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 365;
        validate_non_negative_index("log_input_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> log_input_vector(N_SIZE);
        stan::math::initialize(log_input_vector, DUMMY_VAR__);
        stan::math::fill(log_input_vector, DUMMY_VAR__);
        current_statement_begin__ = 367;
        if (as_bool(use_log)) {
            current_statement_begin__ = 368;
            stan::math::assign(log_input_vector, stan::math::log(input_vector));
            current_statement_begin__ = 369;
            stan::math::assign(result_vector, divide(subtract(log_input_vector, mean(log_input_vector)), sd(log_input_vector)));
        } else {
            current_statement_begin__ = 371;
            stan::math::assign(result_vector, divide(subtract(input_vector, mean(input_vector)), sd(input_vector)));
        }
        current_statement_begin__ = 375;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_vector_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                 const int& use_log, std::ostream* pstream__) const {
        return scale_vector(input_vector, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
unscale_vector(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& original_vector,
                   const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 383;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 384;
        int N_SIZE_ORIGINAL(0);
        (void) N_SIZE_ORIGINAL;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE_ORIGINAL, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE_ORIGINAL,get_base1(dims(original_vector), 1, "dims(original_vector)", 1));
        current_statement_begin__ = 386;
        validate_non_negative_index("log_original_vector", "N_SIZE_ORIGINAL", N_SIZE_ORIGINAL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> log_original_vector(N_SIZE_ORIGINAL);
        stan::math::initialize(log_original_vector, DUMMY_VAR__);
        stan::math::fill(log_original_vector, DUMMY_VAR__);
        current_statement_begin__ = 387;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> result_vector(N_SIZE);
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 390;
        if (as_bool(use_log)) {
            current_statement_begin__ = 392;
            stan::math::assign(log_original_vector, stan::math::log(original_vector));
            current_statement_begin__ = 394;
            stan::math::assign(result_vector, add(multiply(sd(log_original_vector), input_vector), mean(log_original_vector)));
            current_statement_begin__ = 395;
            stan::math::assign(result_vector, stan::math::exp(result_vector));
        } else {
            current_statement_begin__ = 399;
            stan::math::assign(result_vector, add(multiply(sd(original_vector), input_vector), mean(original_vector)));
        }
        current_statement_begin__ = 404;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& input_vector,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& original_vector,
                   const int& use_log, std::ostream* pstream__) const {
        return unscale_vector(input_vector, original_vector, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<typename boost::math::tools::promote_args<T0__, T1__>::type>
unscale_array(const std::vector<T0__>& input_vector,
                  const std::vector<T1__>& original_vector,
                  const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 410;
        int N_SIZE(0);
        (void) N_SIZE;  // dummy to suppress unused var warning
        stan::math::fill(N_SIZE, std::numeric_limits<int>::min());
        stan::math::assign(N_SIZE,get_base1(dims(input_vector), 1, "dims(input_vector)", 1));
        current_statement_begin__ = 412;
        validate_non_negative_index("result_vector", "N_SIZE", N_SIZE);
        std::vector<local_scalar_t__  > result_vector(N_SIZE, local_scalar_t__(DUMMY_VAR__));
        stan::math::initialize(result_vector, DUMMY_VAR__);
        stan::math::fill(result_vector, DUMMY_VAR__);
        current_statement_begin__ = 414;
        stan::math::assign(result_vector, to_array_1d(unscale_vector(to_vector(input_vector), to_vector(original_vector), use_log, pstream__)));
        current_statement_begin__ = 417;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_vector);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<typename boost::math::tools::promote_args<T0__, T1__>::type>
    operator()(const std::vector<T0__>& input_vector,
                  const std::vector<T1__>& original_vector,
                  const int& use_log, std::ostream* pstream__) const {
        return unscale_array(input_vector, original_vector, use_log, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
scale_matrix(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                 const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 423;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 424;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 427;
        validate_non_negative_index("result_matrix", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix(N_ROW, N_COL);
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 429;
        for (int j = 1; j <= N_COL; ++j) {
            current_statement_begin__ = 431;
            stan::model::assign(result_matrix, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        scale_vector(stan::model::rvalue(input_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_matrix"), use_log, pstream__), 
                        "assigning variable result_matrix");
        }
        current_statement_begin__ = 435;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_matrix_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                 const int& use_log, std::ostream* pstream__) const {
        return scale_matrix(input_matrix, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
unscale_matrix(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& original_matrix,
                   const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 441;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 442;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 445;
        validate_non_negative_index("result_matrix", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix(N_ROW, N_COL);
        stan::math::initialize(result_matrix, DUMMY_VAR__);
        stan::math::fill(result_matrix, DUMMY_VAR__);
        current_statement_begin__ = 447;
        for (int j = 1; j <= N_COL; ++j) {
            current_statement_begin__ = 449;
            stan::model::assign(result_matrix, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        unscale_vector(stan::model::rvalue(input_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_matrix"), stan::model::rvalue(original_matrix, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "original_matrix"), use_log, pstream__), 
                        "assigning variable result_matrix");
        }
        current_statement_begin__ = 453;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_matrix_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix,
                   const Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic>& original_matrix,
                   const int& use_log, std::ostream* pstream__) const {
        return unscale_matrix(input_matrix, original_matrix, use_log, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
scale_matrix_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                       const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 459;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_matrix_array), 1, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 460;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix_array), 2, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 461;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix_array), 3, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 464;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        validate_non_negative_index("result_matrix_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(N_ROW, N_COL));
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 466;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 468;
            stan::model::assign(result_matrix_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        scale_matrix(get_base1(input_matrix_array, j, "input_matrix_array", 1), use_log, pstream__), 
                        "assigning variable result_matrix_array");
        }
        current_statement_begin__ = 472;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_matrix_array_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                       const int& use_log, std::ostream* pstream__) const {
        return scale_matrix_array(input_matrix_array, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic> >
unscale_matrix_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic> >& original_matrix_array,
                         const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 479;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_matrix_array), 1, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 480;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix_array), 2, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 481;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix_array), 3, "dims(input_matrix_array)", 1));
        current_statement_begin__ = 484;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        validate_non_negative_index("result_matrix_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>  > result_matrix_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic>(N_ROW, N_COL));
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 486;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 488;
            stan::model::assign(result_matrix_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        unscale_matrix(get_base1(input_matrix_array, j, "input_matrix_array", 1), get_base1(original_matrix_array, j, "original_matrix_array", 1), use_log, pstream__), 
                        "assigning variable result_matrix_array");
        }
        current_statement_begin__ = 492;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_matrix_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, Eigen::Dynamic> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic> >& input_matrix_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, Eigen::Dynamic> >& original_matrix_array,
                         const int& use_log, std::ostream* pstream__) const {
        return unscale_matrix_array(input_matrix_array, original_matrix_array, use_log, pstream__);
    }
};
template <typename T0__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
scale_vector_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                       const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 499;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_vector_array), 1, "dims(input_vector_array)", 1));
        current_statement_begin__ = 500;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input_vector_array), 2, "dims(input_vector_array)", 1));
        current_statement_begin__ = 503;
        validate_non_negative_index("result_array", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result_array, DUMMY_VAR__);
        stan::math::fill(result_array, DUMMY_VAR__);
        current_statement_begin__ = 505;
        for (int j = 1; j <= ARRAY_LENGTH; ++j) {
            current_statement_begin__ = 507;
            stan::model::assign(result_array, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        scale_vector(get_base1(input_vector_array, j, "input_vector_array", 1), use_log, pstream__), 
                        "assigning variable result_array");
        }
        current_statement_begin__ = 511;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct scale_vector_array_functor__ {
    template <typename T0__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                       const int& use_log, std::ostream* pstream__) const {
        return scale_vector_array(input_vector_array, use_log, pstream__);
    }
};
template <typename T0__, typename T1__>
std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1> >
unscale_vector_array(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, 1> >& original_vector_array,
                         const int& use_log, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 519;
        int ARRAY_LENGTH(0);
        (void) ARRAY_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(ARRAY_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(ARRAY_LENGTH,get_base1(dims(input_vector_array), 1, "dims(input_vector_array)", 1));
        current_statement_begin__ = 520;
        int VECTOR_LENGTH(0);
        (void) VECTOR_LENGTH;  // dummy to suppress unused var warning
        stan::math::fill(VECTOR_LENGTH, std::numeric_limits<int>::min());
        stan::math::assign(VECTOR_LENGTH,get_base1(dims(input_vector_array), 2, "dims(input_vector_array)", 1));
        current_statement_begin__ = 523;
        validate_non_negative_index("result_array", "VECTOR_LENGTH", VECTOR_LENGTH);
        validate_non_negative_index("result_array", "ARRAY_LENGTH", ARRAY_LENGTH);
        std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > result_array(ARRAY_LENGTH, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>(VECTOR_LENGTH));
        stan::math::initialize(result_array, DUMMY_VAR__);
        stan::math::fill(result_array, DUMMY_VAR__);
        current_statement_begin__ = 525;
        for (int j = 1; j <= VECTOR_LENGTH; ++j) {
            current_statement_begin__ = 527;
            stan::model::assign(result_array, 
                        stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                        unscale_array(stan::model::rvalue(input_vector_array, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "input_vector_array"), stan::model::rvalue(original_vector_array, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), "original_vector_array"), use_log, pstream__), 
                        "assigning variable result_array");
        }
        current_statement_begin__ = 531;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct unscale_vector_array_functor__ {
    template <typename T0__, typename T1__>
        std::vector<Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1> >
    operator()(const std::vector<Eigen::Matrix<T0__, Eigen::Dynamic, 1> >& input_vector_array,
                         const std::vector<Eigen::Matrix<T1__, Eigen::Dynamic, 1> >& original_vector_array,
                         const int& use_log, std::ostream* pstream__) const {
        return unscale_vector_array(input_vector_array, original_vector_array, use_log, pstream__);
    }
};
template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
cov_matrix_correction(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 537;
        int N_ROW(0);
        (void) N_ROW;  // dummy to suppress unused var warning
        stan::math::fill(N_ROW, std::numeric_limits<int>::min());
        stan::math::assign(N_ROW,get_base1(dims(input_matrix), 1, "dims(input_matrix)", 1));
        current_statement_begin__ = 538;
        int N_COL(0);
        (void) N_COL;  // dummy to suppress unused var warning
        stan::math::fill(N_COL, std::numeric_limits<int>::min());
        stan::math::assign(N_COL,get_base1(dims(input_matrix), 2, "dims(input_matrix)", 1));
        current_statement_begin__ = 540;
        validate_non_negative_index("result_matrix_array", "N_ROW", N_ROW);
        validate_non_negative_index("result_matrix_array", "N_COL", N_COL);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> result_matrix_array(N_ROW, N_COL);
        stan::math::initialize(result_matrix_array, DUMMY_VAR__);
        stan::math::fill(result_matrix_array, DUMMY_VAR__);
        current_statement_begin__ = 542;
        stan::math::assign(result_matrix_array, add(multiply(0.5, add(input_matrix, transpose(input_matrix))), diag_matrix(rep_vector(1e-9, N_ROW))));
        current_statement_begin__ = 545;
        return stan::math::promote_scalar<fun_return_scalar_t__>(result_matrix_array);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}
struct cov_matrix_correction_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& input_matrix, std::ostream* pstream__) const {
        return cov_matrix_correction(input_matrix, pstream__);
    }
};
#include <stan_meta_header.hpp>
class model_matrix_model
  : public stan::model::model_base_crtp<model_matrix_model> {
private:
        int T;
        int T0;
        int K;
        int P;
        int R;
        std::vector<matrix_d> y;
        std::vector<matrix_d> X;
        int keep_theta_static_for_prediction;
        int use_log;
        int scale;
        int T_after;
        std::vector<vector_d> y_vector;
public:
    model_matrix_model(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, 0, pstream__);
    }
    model_matrix_model(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, random_seed__, pstream__);
    }
    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        typedef double local_scalar_t__;
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning
        current_statement_begin__ = -1;
        static const char* function__ = "model_matrix_model_namespace::model_matrix_model";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
        try {
            // initialize data block variables from context__
            current_statement_begin__ = 559;
            context__.validate_dims("data initialization", "T", "int", context__.to_vec());
            T = int(0);
            vals_i__ = context__.vals_i("T");
            pos__ = 0;
            T = vals_i__[pos__++];
            current_statement_begin__ = 560;
            context__.validate_dims("data initialization", "T0", "int", context__.to_vec());
            T0 = int(0);
            vals_i__ = context__.vals_i("T0");
            pos__ = 0;
            T0 = vals_i__[pos__++];
            current_statement_begin__ = 563;
            context__.validate_dims("data initialization", "K", "int", context__.to_vec());
            K = int(0);
            vals_i__ = context__.vals_i("K");
            pos__ = 0;
            K = vals_i__[pos__++];
            current_statement_begin__ = 564;
            context__.validate_dims("data initialization", "P", "int", context__.to_vec());
            P = int(0);
            vals_i__ = context__.vals_i("P");
            pos__ = 0;
            P = vals_i__[pos__++];
            current_statement_begin__ = 565;
            context__.validate_dims("data initialization", "R", "int", context__.to_vec());
            R = int(0);
            vals_i__ = context__.vals_i("R");
            pos__ = 0;
            R = vals_i__[pos__++];
            current_statement_begin__ = 569;
            validate_non_negative_index("y", "R", R);
            validate_non_negative_index("y", "K", K);
            validate_non_negative_index("y", "T0", T0);
            context__.validate_dims("data initialization", "y", "matrix_d", context__.to_vec(T0,R,K));
            y = std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> >(T0, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            vals_r__ = context__.vals_r("y");
            pos__ = 0;
            size_t y_j_2_max__ = K;
            size_t y_j_1_max__ = R;
            size_t y_k_0_max__ = T0;
            for (size_t j_2__ = 0; j_2__ < y_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < y_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < y_k_0_max__; ++k_0__) {
                        y[k_0__](j_1__, j_2__) = vals_r__[pos__++];
                    }
                }
            }
            current_statement_begin__ = 570;
            validate_non_negative_index("X", "R", R);
            validate_non_negative_index("X", "P", P);
            validate_non_negative_index("X", "T0", T0);
            context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(T0,R,P));
            X = std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> >(T0, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, P));
            vals_r__ = context__.vals_r("X");
            pos__ = 0;
            size_t X_j_2_max__ = P;
            size_t X_j_1_max__ = R;
            size_t X_k_0_max__ = T0;
            for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < X_k_0_max__; ++k_0__) {
                        X[k_0__](j_1__, j_2__) = vals_r__[pos__++];
                    }
                }
            }
            current_statement_begin__ = 573;
            context__.validate_dims("data initialization", "keep_theta_static_for_prediction", "int", context__.to_vec());
            keep_theta_static_for_prediction = int(0);
            vals_i__ = context__.vals_i("keep_theta_static_for_prediction");
            pos__ = 0;
            keep_theta_static_for_prediction = vals_i__[pos__++];
            check_greater_or_equal(function__, "keep_theta_static_for_prediction", keep_theta_static_for_prediction, 0);
            check_less_or_equal(function__, "keep_theta_static_for_prediction", keep_theta_static_for_prediction, 1);
            current_statement_begin__ = 575;
            context__.validate_dims("data initialization", "use_log", "int", context__.to_vec());
            use_log = int(0);
            vals_i__ = context__.vals_i("use_log");
            pos__ = 0;
            use_log = vals_i__[pos__++];
            check_greater_or_equal(function__, "use_log", use_log, 0);
            check_less_or_equal(function__, "use_log", use_log, 1);
            current_statement_begin__ = 576;
            context__.validate_dims("data initialization", "scale", "int", context__.to_vec());
            scale = int(0);
            vals_i__ = context__.vals_i("scale");
            pos__ = 0;
            scale = vals_i__[pos__++];
            check_greater_or_equal(function__, "scale", scale, 0);
            check_less_or_equal(function__, "scale", scale, 1);
            // initialize transformed data variables
            current_statement_begin__ = 582;
            T_after = int(0);
            stan::math::fill(T_after, std::numeric_limits<int>::min());
            stan::math::assign(T_after,(T - T0));
            current_statement_begin__ = 584;
            validate_non_negative_index("y_vector", "(R * K)", (R * K));
            validate_non_negative_index("y_vector", "T", T);
            y_vector = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >(T, Eigen::Matrix<double, Eigen::Dynamic, 1>((R * K)));
            stan::math::fill(y_vector, DUMMY_VAR__);
            // execute transformed data statements
            current_statement_begin__ = 587;
            for (int t = 1; t <= T; ++t) {
                current_statement_begin__ = 589;
                if (as_bool(scale)) {
                    current_statement_begin__ = 591;
                    stan::model::assign(y_vector, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                to_vector(scale_matrix(get_base1(y, t, "y", 1), use_log, pstream__)), 
                                "assigning variable y_vector");
                } else {
                    current_statement_begin__ = 595;
                    if (as_bool(use_log)) {
                        current_statement_begin__ = 597;
                        stan::model::assign(y_vector, 
                                    stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                    to_vector(stan::math::log(get_base1(y, t, "y", 1))), 
                                    "assigning variable y_vector");
                    } else {
                        current_statement_begin__ = 600;
                        stan::model::assign(y_vector, 
                                    stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                    to_vector(get_base1(y, t, "y", 1)), 
                                    "assigning variable y_vector");
                    }
                }
            }
            // validate transformed data
            // validate, set parameter ranges
            num_params_r__ = 0U;
            param_ranges_i__.clear();
            current_statement_begin__ = 617;
            validate_non_negative_index("sigma_entry_obs_rows", "R", R);
            validate_non_negative_index("sigma_entry_obs_rows", "R", R);
            num_params_r__ += (R + ((R * (R - 1)) / 2));
            current_statement_begin__ = 618;
            validate_non_negative_index("sigma_entry_obs_cols", "K", K);
            validate_non_negative_index("sigma_entry_obs_cols", "K", K);
            num_params_r__ += (K + ((K * (K - 1)) / 2));
            current_statement_begin__ = 621;
            validate_non_negative_index("level_sigma_rows", "P", P);
            validate_non_negative_index("level_sigma_rows", "P", P);
            num_params_r__ += (P + ((P * (P - 1)) / 2));
            current_statement_begin__ = 622;
            validate_non_negative_index("level_sigma_cols", "K", K);
            validate_non_negative_index("level_sigma_cols", "K", K);
            num_params_r__ += (K + ((K * (K - 1)) / 2));
            current_statement_begin__ = 625;
            validate_non_negative_index("theta", "(P * K)", (P * K));
            validate_non_negative_index("theta", "T0", T0);
            num_params_r__ += ((P * K) * T0);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }
    ~model_matrix_model() { }
    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        typedef double local_scalar_t__;
        stan::io::writer<double> writer__(params_r__, params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;
        current_statement_begin__ = 617;
        if (!(context__.contains_r("sigma_entry_obs_rows")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable sigma_entry_obs_rows missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("sigma_entry_obs_rows");
        pos__ = 0U;
        validate_non_negative_index("sigma_entry_obs_rows", "R", R);
        validate_non_negative_index("sigma_entry_obs_rows", "R", R);
        context__.validate_dims("parameter initialization", "sigma_entry_obs_rows", "matrix_d", context__.to_vec(R,R));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_rows(R, R);
        size_t sigma_entry_obs_rows_j_2_max__ = R;
        size_t sigma_entry_obs_rows_j_1_max__ = R;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_rows_j_1_max__; ++j_1__) {
                sigma_entry_obs_rows(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cov_matrix_unconstrain(sigma_entry_obs_rows);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable sigma_entry_obs_rows: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 618;
        if (!(context__.contains_r("sigma_entry_obs_cols")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable sigma_entry_obs_cols missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("sigma_entry_obs_cols");
        pos__ = 0U;
        validate_non_negative_index("sigma_entry_obs_cols", "K", K);
        validate_non_negative_index("sigma_entry_obs_cols", "K", K);
        context__.validate_dims("parameter initialization", "sigma_entry_obs_cols", "matrix_d", context__.to_vec(K,K));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_cols(K, K);
        size_t sigma_entry_obs_cols_j_2_max__ = K;
        size_t sigma_entry_obs_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_cols_j_1_max__; ++j_1__) {
                sigma_entry_obs_cols(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cov_matrix_unconstrain(sigma_entry_obs_cols);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable sigma_entry_obs_cols: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 621;
        if (!(context__.contains_r("level_sigma_rows")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable level_sigma_rows missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("level_sigma_rows");
        pos__ = 0U;
        validate_non_negative_index("level_sigma_rows", "P", P);
        validate_non_negative_index("level_sigma_rows", "P", P);
        context__.validate_dims("parameter initialization", "level_sigma_rows", "matrix_d", context__.to_vec(P,P));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> level_sigma_rows(P, P);
        size_t level_sigma_rows_j_2_max__ = P;
        size_t level_sigma_rows_j_1_max__ = P;
        for (size_t j_2__ = 0; j_2__ < level_sigma_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_rows_j_1_max__; ++j_1__) {
                level_sigma_rows(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cov_matrix_unconstrain(level_sigma_rows);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable level_sigma_rows: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 622;
        if (!(context__.contains_r("level_sigma_cols")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable level_sigma_cols missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("level_sigma_cols");
        pos__ = 0U;
        validate_non_negative_index("level_sigma_cols", "K", K);
        validate_non_negative_index("level_sigma_cols", "K", K);
        context__.validate_dims("parameter initialization", "level_sigma_cols", "matrix_d", context__.to_vec(K,K));
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> level_sigma_cols(K, K);
        size_t level_sigma_cols_j_2_max__ = K;
        size_t level_sigma_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < level_sigma_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_cols_j_1_max__; ++j_1__) {
                level_sigma_cols(j_1__, j_2__) = vals_r__[pos__++];
            }
        }
        try {
            writer__.cov_matrix_unconstrain(level_sigma_cols);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable level_sigma_cols: ") + e.what()), current_statement_begin__, prog_reader__());
        }
        current_statement_begin__ = 625;
        if (!(context__.contains_r("theta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable theta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("theta");
        pos__ = 0U;
        validate_non_negative_index("theta", "(P * K)", (P * K));
        validate_non_negative_index("theta", "T0", T0);
        context__.validate_dims("parameter initialization", "theta", "vector_d", context__.to_vec(T0,(P * K)));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > theta(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>((P * K)));
        size_t theta_j_1_max__ = (P * K);
        size_t theta_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_k_0_max__; ++k_0__) {
                theta[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t theta_i_0_max__ = T0;
        for (size_t i_0__ = 0; i_0__ < theta_i_0_max__; ++i_0__) {
            try {
                writer__.vector_unconstrain(theta[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable theta: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }
        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }
    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double, Eigen::Dynamic, 1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }
    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(std::vector<T__>& params_r__,
                 std::vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {
        typedef T__ local_scalar_t__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // dummy to suppress unused var warning
        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;
        try {
            stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
            // model parameters
            current_statement_begin__ = 617;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_rows;
            (void) sigma_entry_obs_rows;  // dummy to suppress unused var warning
            if (jacobian__)
                sigma_entry_obs_rows = in__.cov_matrix_constrain(R, lp__);
            else
                sigma_entry_obs_rows = in__.cov_matrix_constrain(R);
            current_statement_begin__ = 618;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_cols;
            (void) sigma_entry_obs_cols;  // dummy to suppress unused var warning
            if (jacobian__)
                sigma_entry_obs_cols = in__.cov_matrix_constrain(K, lp__);
            else
                sigma_entry_obs_cols = in__.cov_matrix_constrain(K);
            current_statement_begin__ = 621;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> level_sigma_rows;
            (void) level_sigma_rows;  // dummy to suppress unused var warning
            if (jacobian__)
                level_sigma_rows = in__.cov_matrix_constrain(P, lp__);
            else
                level_sigma_rows = in__.cov_matrix_constrain(P);
            current_statement_begin__ = 622;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> level_sigma_cols;
            (void) level_sigma_cols;  // dummy to suppress unused var warning
            if (jacobian__)
                level_sigma_cols = in__.cov_matrix_constrain(K, lp__);
            else
                level_sigma_cols = in__.cov_matrix_constrain(K);
            current_statement_begin__ = 625;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > theta;
            size_t theta_d_0_max__ = T0;
            theta.reserve(theta_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < theta_d_0_max__; ++d_0__) {
                if (jacobian__)
                    theta.push_back(in__.vector_constrain((P * K), lp__));
                else
                    theta.push_back(in__.vector_constrain((P * K)));
            }
            // model body
            {
            current_statement_begin__ = 634;
            validate_non_negative_index("mu", "(R * K)", (R * K));
            validate_non_negative_index("mu", "T0", T0);
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>  > mu(T0, Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>((R * K)));
            stan::math::initialize(mu, DUMMY_VAR__);
            stan::math::fill(mu, DUMMY_VAR__);
            current_statement_begin__ = 641;
            stan::model::assign(mu, 
                        stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                        to_vector(multiply(get_base1(X, 1, "X", 1), to_matrix(get_base1(theta, 1, "theta", 1), P, K))), 
                        "assigning variable mu");
            current_statement_begin__ = 644;
            for (int t = 2; t <= T0; ++t) {
                current_statement_begin__ = 646;
                stan::model::assign(mu, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_vector(multiply(get_base1(X, t, "X", 1), to_matrix(get_base1(theta, t, "theta", 1), P, K))), 
                            "assigning variable mu");
            }
            current_statement_begin__ = 651;
            lp_accum__.add(inv_wishart_log<propto__>(sigma_entry_obs_cols, (1.0 * K), diag_matrix(rep_vector(100, K))));
            current_statement_begin__ = 656;
            lp_accum__.add(inv_wishart_log<propto__>(sigma_entry_obs_rows, (1.0 * R), diag_matrix(rep_vector(100, R))));
            current_statement_begin__ = 660;
            lp_accum__.add(inv_wishart_log<propto__>(level_sigma_rows, (1.0 * P), diag_matrix(rep_vector(100, P))));
            current_statement_begin__ = 661;
            lp_accum__.add(inv_wishart_log<propto__>(level_sigma_cols, (1.0 * K), diag_matrix(rep_vector(100, K))));
            current_statement_begin__ = 666;
            for (int t = 1; t <= T0; ++t) {
                current_statement_begin__ = 668;
                if (as_bool(logical_lte(t, 1))) {
                    current_statement_begin__ = 671;
                    lp_accum__.add(multi_normal_log<propto__>(get_base1(theta, t, "theta", 1), rep_vector(0.0, (P * K)), cov_matrix_correction(kronecker_prod(diag_matrix(rep_vector(1, P)), diag_matrix(rep_vector(1, K)), pstream__), pstream__)));
                } else {
                    current_statement_begin__ = 677;
                    lp_accum__.add(multi_normal_log<propto__>(get_base1(theta, t, "theta", 1), get_base1(theta, (t - 1), "theta", 1), cov_matrix_correction(kronecker_prod(level_sigma_rows, level_sigma_cols, pstream__), pstream__)));
                }
            }
            current_statement_begin__ = 683;
            for (int t = 2; t <= T0; ++t) {
                current_statement_begin__ = 686;
                lp_accum__.add(multi_normal_log<propto__>(get_base1(y_vector, t, "y_vector", 1), get_base1(mu, t, "mu", 1), cov_matrix_correction(kronecker_prod(sigma_entry_obs_rows, sigma_entry_obs_cols, pstream__), pstream__)));
            }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
        lp_accum__.add(lp__);
        return lp_accum__.sum();
    } // log_prob()
    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }
    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("sigma_entry_obs_rows");
        names__.push_back("sigma_entry_obs_cols");
        names__.push_back("level_sigma_rows");
        names__.push_back("level_sigma_cols");
        names__.push_back("theta");
        names__.push_back("mu");
        names__.push_back("scaled_Y_pred");
        names__.push_back("Y_pred");
        names__.push_back("theta_pred");
        names__.push_back("mu_pred");
        names__.push_back("difference");
        names__.push_back("cumsum_difference");
        names__.push_back("cumsum_only_after");
        names__.push_back("arco_only_after");
        names__.push_back("arco_only_after_aggregated");
    }
    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(R);
        dims__.push_back(R);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(P);
        dims__.push_back(P);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T0);
        dims__.push_back((P * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T0);
        dims__.push_back((R * K));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(P);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dims__.push_back(R);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(T);
        dimss__.push_back(dims__);
    }
    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        typedef double local_scalar_t__;
        vars__.resize(0);
        stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
        static const char* function__ = "model_matrix_model_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_rows = in__.cov_matrix_constrain(R);
        size_t sigma_entry_obs_rows_j_2_max__ = R;
        size_t sigma_entry_obs_rows_j_1_max__ = R;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_rows_j_1_max__; ++j_1__) {
                vars__.push_back(sigma_entry_obs_rows(j_1__, j_2__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> sigma_entry_obs_cols = in__.cov_matrix_constrain(K);
        size_t sigma_entry_obs_cols_j_2_max__ = K;
        size_t sigma_entry_obs_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_cols_j_1_max__; ++j_1__) {
                vars__.push_back(sigma_entry_obs_cols(j_1__, j_2__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> level_sigma_rows = in__.cov_matrix_constrain(P);
        size_t level_sigma_rows_j_2_max__ = P;
        size_t level_sigma_rows_j_1_max__ = P;
        for (size_t j_2__ = 0; j_2__ < level_sigma_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_rows_j_1_max__; ++j_1__) {
                vars__.push_back(level_sigma_rows(j_1__, j_2__));
            }
        }
        Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> level_sigma_cols = in__.cov_matrix_constrain(K);
        size_t level_sigma_cols_j_2_max__ = K;
        size_t level_sigma_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < level_sigma_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_cols_j_1_max__; ++j_1__) {
                vars__.push_back(level_sigma_cols(j_1__, j_2__));
            }
        }
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > theta;
        size_t theta_d_0_max__ = T0;
        theta.reserve(theta_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < theta_d_0_max__; ++d_0__) {
            theta.push_back(in__.vector_constrain((P * K)));
        }
        size_t theta_j_1_max__ = (P * K);
        size_t theta_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_k_0_max__; ++k_0__) {
                vars__.push_back(theta[k_0__](j_1__));
            }
        }
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning
        if (!include_tparams__ && !include_gqs__) return;
        try {
            if (!include_gqs__ && !include_tparams__) return;
            if (!include_gqs__) return;
            // declare and define generated quantities
            current_statement_begin__ = 696;
            validate_non_negative_index("mu", "(R * K)", (R * K));
            validate_non_negative_index("mu", "T0", T0);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mu(T0, Eigen::Matrix<double, Eigen::Dynamic, 1>((R * K)));
            stan::math::initialize(mu, DUMMY_VAR__);
            stan::math::fill(mu, DUMMY_VAR__);
            current_statement_begin__ = 700;
            validate_non_negative_index("scaled_Y_pred", "R", R);
            validate_non_negative_index("scaled_Y_pred", "K", K);
            validate_non_negative_index("scaled_Y_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > scaled_Y_pred(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(scaled_Y_pred, DUMMY_VAR__);
            stan::math::fill(scaled_Y_pred, DUMMY_VAR__);
            current_statement_begin__ = 701;
            validate_non_negative_index("Y_pred", "R", R);
            validate_non_negative_index("Y_pred", "K", K);
            validate_non_negative_index("Y_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > Y_pred(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(Y_pred, DUMMY_VAR__);
            stan::math::fill(Y_pred, DUMMY_VAR__);
            current_statement_begin__ = 702;
            validate_non_negative_index("theta_pred", "P", P);
            validate_non_negative_index("theta_pred", "K", K);
            validate_non_negative_index("theta_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > theta_pred(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(P, K));
            stan::math::initialize(theta_pred, DUMMY_VAR__);
            stan::math::fill(theta_pred, DUMMY_VAR__);
            current_statement_begin__ = 703;
            validate_non_negative_index("mu_pred", "R", R);
            validate_non_negative_index("mu_pred", "K", K);
            validate_non_negative_index("mu_pred", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > mu_pred(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(mu_pred, DUMMY_VAR__);
            stan::math::fill(mu_pred, DUMMY_VAR__);
            current_statement_begin__ = 704;
            validate_non_negative_index("difference", "R", R);
            validate_non_negative_index("difference", "K", K);
            validate_non_negative_index("difference", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > difference(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(difference, DUMMY_VAR__);
            stan::math::fill(difference, DUMMY_VAR__);
            current_statement_begin__ = 705;
            validate_non_negative_index("cumsum_difference", "R", R);
            validate_non_negative_index("cumsum_difference", "K", K);
            validate_non_negative_index("cumsum_difference", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > cumsum_difference(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(cumsum_difference, DUMMY_VAR__);
            stan::math::fill(cumsum_difference, DUMMY_VAR__);
            current_statement_begin__ = 706;
            validate_non_negative_index("cumsum_only_after", "R", R);
            validate_non_negative_index("cumsum_only_after", "K", K);
            validate_non_negative_index("cumsum_only_after", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > cumsum_only_after(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(cumsum_only_after, DUMMY_VAR__);
            stan::math::fill(cumsum_only_after, DUMMY_VAR__);
            current_statement_begin__ = 709;
            validate_non_negative_index("arco_only_after", "R", R);
            validate_non_negative_index("arco_only_after", "K", K);
            validate_non_negative_index("arco_only_after", "T", T);
            std::vector<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> > arco_only_after(T, Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(R, K));
            stan::math::initialize(arco_only_after, DUMMY_VAR__);
            stan::math::fill(arco_only_after, DUMMY_VAR__);
            current_statement_begin__ = 710;
            validate_non_negative_index("arco_only_after_aggregated", "T", T);
            Eigen::Matrix<double, Eigen::Dynamic, 1> arco_only_after_aggregated(T);
            stan::math::initialize(arco_only_after_aggregated, DUMMY_VAR__);
            stan::math::fill(arco_only_after_aggregated, DUMMY_VAR__);
            // generated quantities statements
            current_statement_begin__ = 714;
            stan::model::assign(mu, 
                        stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                        to_vector(multiply(get_base1(X, 1, "X", 1), to_matrix(get_base1(theta, 1, "theta", 1), P, K))), 
                        "assigning variable mu");
            current_statement_begin__ = 717;
            for (int t = 2; t <= T0; ++t) {
                current_statement_begin__ = 719;
                stan::model::assign(mu, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_vector(multiply(get_base1(X, t, "X", 1), to_matrix(get_base1(theta, t, "theta", 1), P, K))), 
                            "assigning variable mu");
            }
            current_statement_begin__ = 725;
            for (int t = 1; t <= T0; ++t) {
                current_statement_begin__ = 727;
                stan::model::assign(theta_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_matrix(get_base1(theta, t, "theta", 1), P, K), 
                            "assigning variable theta_pred");
                current_statement_begin__ = 729;
                stan::model::assign(mu_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_matrix(get_base1(mu, t, "mu", 1), R, K), 
                            "assigning variable mu_pred");
                current_statement_begin__ = 734;
                stan::model::assign(scaled_Y_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_matrix(multi_normal_rng(to_vector(get_base1(mu_pred, t, "mu_pred", 1)), cov_matrix_correction(kronecker_prod(sigma_entry_obs_rows, sigma_entry_obs_cols, pstream__), pstream__), base_rng__), R, K), 
                            "assigning variable scaled_Y_pred");
                current_statement_begin__ = 737;
                stan::model::assign(difference, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            subtract(get_base1(y, t, "y", 1), get_base1(scaled_Y_pred, t, "scaled_Y_pred", 1)), 
                            "assigning variable difference");
                current_statement_begin__ = 740;
                stan::model::assign(cumsum_only_after, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_matrix(rep_vector(0, (R * K)), R, K), 
                            "assigning variable cumsum_only_after");
            }
            current_statement_begin__ = 744;
            for (int t = (T0 + 1); t <= T; ++t) {
                current_statement_begin__ = 747;
                if (as_bool(keep_theta_static_for_prediction)) {
                    current_statement_begin__ = 750;
                    stan::model::assign(theta_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                get_base1(theta_pred, T0, "theta_pred", 1), 
                                "assigning variable theta_pred");
                } else {
                    current_statement_begin__ = 754;
                    stan::model::assign(theta_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                to_matrix(multi_normal_rng(to_vector(get_base1(theta_pred, (t - 1), "theta_pred", 1)), cov_matrix_correction(kronecker_prod(level_sigma_rows, level_sigma_cols, pstream__), pstream__), base_rng__), P, K), 
                                "assigning variable theta_pred");
                }
                current_statement_begin__ = 757;
                stan::model::assign(mu_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            multiply(get_base1(X, t, "X", 1), get_base1(theta_pred, t, "theta_pred", 1)), 
                            "assigning variable mu_pred");
                current_statement_begin__ = 759;
                stan::model::assign(scaled_Y_pred, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            to_matrix(multi_normal_rng(to_vector(get_base1(mu_pred, t, "mu_pred", 1)), cov_matrix_correction(kronecker_prod(level_sigma_rows, level_sigma_cols, pstream__), pstream__), base_rng__), R, K), 
                            "assigning variable scaled_Y_pred");
                current_statement_begin__ = 763;
                if (as_bool(scale)) {
                    current_statement_begin__ = 765;
                    stan::model::assign(Y_pred, 
                                stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                unscale_matrix(get_base1(scaled_Y_pred, t, "scaled_Y_pred", 1), get_base1(y, t, "y", 1), use_log, pstream__), 
                                "assigning variable Y_pred");
                } else {
                    current_statement_begin__ = 769;
                    if (as_bool(use_log)) {
                        current_statement_begin__ = 771;
                        stan::model::assign(Y_pred, 
                                    stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                    stan::math::exp(get_base1(scaled_Y_pred, t, "scaled_Y_pred", 1)), 
                                    "assigning variable Y_pred");
                    } else {
                        current_statement_begin__ = 774;
                        stan::model::assign(Y_pred, 
                                    stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                                    get_base1(scaled_Y_pred, t, "scaled_Y_pred", 1), 
                                    "assigning variable Y_pred");
                    }
                }
                current_statement_begin__ = 780;
                stan::model::assign(difference, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            subtract(get_base1(y, t, "y", 1), get_base1(Y_pred, t, "Y_pred", 1)), 
                            "assigning variable difference");
            }
            current_statement_begin__ = 785;
            stan::math::assign(cumsum_difference, cumsum_matrix(difference, pstream__));
            current_statement_begin__ = 786;
            stan::model::assign(cumsum_only_after, 
                        stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), 
                        cumsum_matrix(stan::model::rvalue(difference, stan::model::cons_list(stan::model::index_min_max((T0 + 1), T), stan::model::nil_index_list()), "difference"), pstream__), 
                        "assigning variable cumsum_only_after");
            current_statement_begin__ = 789;
            for (int t = (T0 + 1); t <= T; ++t) {
                current_statement_begin__ = 791;
                stan::model::assign(arco_only_after, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            multiply((1.0 / (t - T0)), get_base1(cumsum_only_after, t, "cumsum_only_after", 1)), 
                            "assigning variable arco_only_after");
                current_statement_begin__ = 792;
                stan::model::assign(arco_only_after_aggregated, 
                            stan::model::cons_list(stan::model::index_uni(t), stan::model::nil_index_list()), 
                            mean(get_base1(arco_only_after, t, "arco_only_after", 1)), 
                            "assigning variable arco_only_after_aggregated");
            }
            // validate, write generated quantities
            current_statement_begin__ = 696;
            size_t mu_j_1_max__ = (R * K);
            size_t mu_k_0_max__ = T0;
            for (size_t j_1__ = 0; j_1__ < mu_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < mu_k_0_max__; ++k_0__) {
                    vars__.push_back(mu[k_0__](j_1__));
                }
            }
            current_statement_begin__ = 700;
            size_t scaled_Y_pred_j_2_max__ = K;
            size_t scaled_Y_pred_j_1_max__ = R;
            size_t scaled_Y_pred_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < scaled_Y_pred_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                        vars__.push_back(scaled_Y_pred[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 701;
            size_t Y_pred_j_2_max__ = K;
            size_t Y_pred_j_1_max__ = R;
            size_t Y_pred_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < Y_pred_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                        vars__.push_back(Y_pred[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 702;
            size_t theta_pred_j_2_max__ = K;
            size_t theta_pred_j_1_max__ = P;
            size_t theta_pred_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < theta_pred_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < theta_pred_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < theta_pred_k_0_max__; ++k_0__) {
                        vars__.push_back(theta_pred[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 703;
            size_t mu_pred_j_2_max__ = K;
            size_t mu_pred_j_1_max__ = R;
            size_t mu_pred_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < mu_pred_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                        vars__.push_back(mu_pred[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 704;
            size_t difference_j_2_max__ = K;
            size_t difference_j_1_max__ = R;
            size_t difference_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < difference_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                        vars__.push_back(difference[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 705;
            size_t cumsum_difference_j_2_max__ = K;
            size_t cumsum_difference_j_1_max__ = R;
            size_t cumsum_difference_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < cumsum_difference_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                        vars__.push_back(cumsum_difference[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 706;
            size_t cumsum_only_after_j_2_max__ = K;
            size_t cumsum_only_after_j_1_max__ = R;
            size_t cumsum_only_after_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < cumsum_only_after_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                        vars__.push_back(cumsum_only_after[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 709;
            size_t arco_only_after_j_2_max__ = K;
            size_t arco_only_after_j_1_max__ = R;
            size_t arco_only_after_k_0_max__ = T;
            for (size_t j_2__ = 0; j_2__ < arco_only_after_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
                    for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                        vars__.push_back(arco_only_after[k_0__](j_1__, j_2__));
                    }
                }
            }
            current_statement_begin__ = 710;
            size_t arco_only_after_aggregated_j_1_max__ = T;
            for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
                vars__.push_back(arco_only_after_aggregated(j_1__));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }
    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng, params_r_vec, params_i_vec, vars_vec, include_tparams, include_gqs, pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }
    std::string model_name() const {
        return "model_matrix_model";
    }
    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t sigma_entry_obs_rows_j_2_max__ = R;
        size_t sigma_entry_obs_rows_j_1_max__ = R;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_rows_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "sigma_entry_obs_rows" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t sigma_entry_obs_cols_j_2_max__ = K;
        size_t sigma_entry_obs_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < sigma_entry_obs_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_cols_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "sigma_entry_obs_cols" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t level_sigma_rows_j_2_max__ = P;
        size_t level_sigma_rows_j_1_max__ = P;
        for (size_t j_2__ = 0; j_2__ < level_sigma_rows_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_rows_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "level_sigma_rows" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t level_sigma_cols_j_2_max__ = K;
        size_t level_sigma_cols_j_1_max__ = K;
        for (size_t j_2__ = 0; j_2__ < level_sigma_cols_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < level_sigma_cols_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "level_sigma_cols" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t theta_j_1_max__ = (P * K);
        size_t theta_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        if (!include_gqs__ && !include_tparams__) return;
        if (include_tparams__) {
        }
        if (!include_gqs__) return;
        size_t mu_j_1_max__ = (R * K);
        size_t mu_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < mu_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mu_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mu" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t scaled_Y_pred_j_2_max__ = K;
        size_t scaled_Y_pred_j_1_max__ = R;
        size_t scaled_Y_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < scaled_Y_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "scaled_Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t Y_pred_j_2_max__ = K;
        size_t Y_pred_j_1_max__ = R;
        size_t Y_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < Y_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t theta_pred_j_2_max__ = K;
        size_t theta_pred_j_1_max__ = P;
        size_t theta_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < theta_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < theta_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < theta_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "theta_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t mu_pred_j_2_max__ = K;
        size_t mu_pred_j_1_max__ = R;
        size_t mu_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < mu_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "mu_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t difference_j_2_max__ = K;
        size_t difference_j_1_max__ = R;
        size_t difference_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < difference_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t cumsum_difference_j_2_max__ = K;
        size_t cumsum_difference_j_1_max__ = R;
        size_t cumsum_difference_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < cumsum_difference_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "cumsum_difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t cumsum_only_after_j_2_max__ = K;
        size_t cumsum_only_after_j_1_max__ = R;
        size_t cumsum_only_after_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < cumsum_only_after_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "cumsum_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t arco_only_after_j_2_max__ = K;
        size_t arco_only_after_j_1_max__ = R;
        size_t arco_only_after_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < arco_only_after_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "arco_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t arco_only_after_aggregated_j_1_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "arco_only_after_aggregated" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
    }
    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t sigma_entry_obs_rows_j_1_max__ = (R + ((R * (R - 1)) / 2));
        for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_rows_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma_entry_obs_rows" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t sigma_entry_obs_cols_j_1_max__ = (K + ((K * (K - 1)) / 2));
        for (size_t j_1__ = 0; j_1__ < sigma_entry_obs_cols_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma_entry_obs_cols" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t level_sigma_rows_j_1_max__ = (P + ((P * (P - 1)) / 2));
        for (size_t j_1__ = 0; j_1__ < level_sigma_rows_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "level_sigma_rows" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t level_sigma_cols_j_1_max__ = (K + ((K * (K - 1)) / 2));
        for (size_t j_1__ = 0; j_1__ < level_sigma_cols_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "level_sigma_cols" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_j_1_max__ = (P * K);
        size_t theta_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < theta_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < theta_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        if (!include_gqs__ && !include_tparams__) return;
        if (include_tparams__) {
        }
        if (!include_gqs__) return;
        size_t mu_j_1_max__ = (R * K);
        size_t mu_k_0_max__ = T0;
        for (size_t j_1__ = 0; j_1__ < mu_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mu_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mu" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t scaled_Y_pred_j_2_max__ = K;
        size_t scaled_Y_pred_j_1_max__ = R;
        size_t scaled_Y_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < scaled_Y_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < scaled_Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < scaled_Y_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "scaled_Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t Y_pred_j_2_max__ = K;
        size_t Y_pred_j_1_max__ = R;
        size_t Y_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < Y_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < Y_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < Y_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "Y_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t theta_pred_j_2_max__ = K;
        size_t theta_pred_j_1_max__ = P;
        size_t theta_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < theta_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < theta_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < theta_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "theta_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t mu_pred_j_2_max__ = K;
        size_t mu_pred_j_1_max__ = R;
        size_t mu_pred_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < mu_pred_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < mu_pred_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < mu_pred_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "mu_pred" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t difference_j_2_max__ = K;
        size_t difference_j_1_max__ = R;
        size_t difference_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < difference_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < difference_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t cumsum_difference_j_2_max__ = K;
        size_t cumsum_difference_j_1_max__ = R;
        size_t cumsum_difference_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < cumsum_difference_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < cumsum_difference_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_difference_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "cumsum_difference" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t cumsum_only_after_j_2_max__ = K;
        size_t cumsum_only_after_j_1_max__ = R;
        size_t cumsum_only_after_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < cumsum_only_after_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < cumsum_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < cumsum_only_after_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "cumsum_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t arco_only_after_j_2_max__ = K;
        size_t arco_only_after_j_1_max__ = R;
        size_t arco_only_after_k_0_max__ = T;
        for (size_t j_2__ = 0; j_2__ < arco_only_after_j_2_max__; ++j_2__) {
            for (size_t j_1__ = 0; j_1__ < arco_only_after_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < arco_only_after_k_0_max__; ++k_0__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "arco_only_after" << '.' << k_0__ + 1 << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
        }
        size_t arco_only_after_aggregated_j_1_max__ = T;
        for (size_t j_1__ = 0; j_1__ < arco_only_after_aggregated_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "arco_only_after_aggregated" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
    }
}; // model
}  // namespace
typedef model_matrix_model_namespace::model_matrix_model stan_model;
#ifndef USING_R
stan::model::model_base& new_model(
        stan::io::var_context& data_context,
        unsigned int seed,
        std::ostream* msg_stream) {
  stan_model* m = new stan_model(data_context, seed, msg_stream);
  return *m;
}
#endif
#endif
